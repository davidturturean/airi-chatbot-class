Repository ID: RID-PREP-0052
Source: AI_Risk_Repository_Preprint.docx
Section: Unknown
Content Type: comparative_analysis
Word Count: 794

Content:
(2021). A Local Law to amend the administrative code of the city of New York, in relation to automated employment decision tools. https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4344524&GUID=B051915D-A9AC-451E-81F8-6596032FA3F9&Options=ID%7cText%7c&Search= Corbin, J., & Strauss, A. (2014). Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory. SAGE Publications. https://play.google.com/store/books/details?id=hZ6kBQAAQBAJ Costanza-Chock, S., Raji, I. D., & Buolamwini, J. (2022). Who Audits the Auditors? Recommendations from a field scan of the algorithmic auditing ecosystem. Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency, 1571–1583. https://doi.org/10.1145/3531146.3533213 Critch, A., & Russell, S. (2023). TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI. In arXiv [cs.AI]. arXiv. http://arxiv.org/abs/2306.06924 Cui, T., Wang, Y., Fu, C., Xiao, Y., Li, S., Deng, X., Liu, Y., Zhang, Q., Qiu, Z., Li, P., Tan, Z., Xiong, J., Kong, X., Wen, Z., Xu, K., & Li, Q. (2024). Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems. In arXiv [cs.CL]. arXiv. http://arxiv.org/abs/2401.05778 Cunha, P. R., & Estima, J. (2023). Navigating the landscape of AI ethics and responsibility. In Progress in Artificial Intelligence (pp. 92–105). Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-49008-8_8 Deng, J., Cheng, J., Sun, H., Zhang, Z., & Huang, M. (2023). Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements. In arXiv [cs.AI]. arXiv. http://arxiv.org/abs/2302.09270 Department for Science, & Technology. (2024, May 17). Safety of advanced AI under the spotlight in first ever independent, international scientific report. GOV.UK. https://www.gov.uk/government/news/safety-of-advanced-ai-under-the-spotlight-in-first-ever-independent-international-scientific-report Electronic Privacy Information Centre. (2023). Generating Harms: Generative AI’s Impact & Paths Forward. {Electronic Privacy Information Centre}. Elliott, J. H., Synnot, A., Turner, T., Simmonds, M., Akl, E. A., McDonald, S., Salanti, G., Meerpohl, J., MacLehose, H., Hilton, J., Tovey, D., Shemilt, I., Thomas, J., & Living Systematic Review Network. (2017). Living systematic review: 1. Introduction-the why, what, when, and how. Journal of Clinical Epidemiology, 91, 23–30. https://doi.org/10.1016/j.jclinepi.2017.08.010 Epoch AI. (2024). Data on Notable AI Models [Dataset]. https://epochai.org/data/notable-ai-models European Commission. (COM/2021/206ﬁnal, 2021/0106(COD), 2021). Proposal For a Regulation of The European Parliament andof The Council Laying Down Harmonised Rules on Artiﬁcial Intelligence (ArtiﬁcialIntelligence Act) and Amending Certain Union Legislative Acts. https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A52021PC0206 European Commission and the United States Trade and Technology Council. (2022). TTC Joint Roadmap for Trustworthy AI and Risk Management. European Commission . European Parliament. (2024). Legislative resolution of 13 March 2024 on the Proposal for a Regulation of the European Parliament and of the Council on laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union Legislative Acts. https://www.europarl.europa.eu/doceo/document/TA-9-2024-0138_EN.html Executive Office of the President. (2023, October). Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. Federal Register. https://www.federalregister.gov/documents/2023/11/01/2023-24283/ safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence Fang, Z., Dudek, J., Noyons, E., & Costas, R. (2020). Science cited in policy documents: Evidence from the Overton database. Altmetrics Conference. https://altmetrics.org/wp-content/uploads/2020/11/02_submission_Fang_Dudek_Noyons_Costas-altmetrics20.pdf Ferdinands, G., Schram, R., de Bruin, J., Bagheri, A., Oberski, D. L., Tummers, L., Teijema, J. J., & van de Schoot, R. (2023). Performance of active learning models for screening prioritization in systematic reviews: a simulation study into the Average Time to Discover relevant records. Systematic Reviews, 12(1), 100. https://doi.org/10.1186/s13643-023-02257-7 Ferrara, E. (2024). GenAI against humanity: nefarious applications of generative artificial intelligence and large language models. Journal of Computational Social Science, 7(1), 549–569. https://doi.org/10.1007/s42001-024-00250-1 Francken, J. C., Beerendonk, L., Molenaar, D., Fahrenfort, J. J., Kiverstein, J. D., Seth, A. K., & van Gaal, S. (2022). An academic survey on theoretical foundations, common assumptions and the current state of consciousness science. Neuroscience of Consciousness, 2022(1), niac011. https://doi.org/10.1093/nc/niac011 Gabriel, I., Manzini, A., Keeling, G., Hendricks, L. A., Rieser, V., Iqbal, H., Tomašev, N., Ktena, I., Kenton, Z., Rodriguez, M., El-Sayed, S., Brown, S., Akbulut, C., Trask, A., Hughes, E., Stevie Bergman, A., Shelby, R., Marchal, N., Griffin, C., … Manyika, J. (2024). The Ethics of Advanced AI Assistants. In arXiv. Google DeepMind. https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/ethics-of-advanced-ai-assistants/the-ethics-of-advanced-ai-assistants-2024-i.pdf Gates, A., Guitard, S., Pillay, J., Elliott, S. A., Dyson, M. P., Newton, A. S., & Hartling, L. (2019). Performance and usability of machine learning for screening in systematic reviews: a comparative evaluation of three tools. Systematic Reviews, 8(1), 278. https://doi.org/10.1186/s13643-019-1222-2 Ghosh, S., Frase, H., Williams, A., Luger, S., Röttger, P., Barez, F., McGregor, S., Fricklas, K., Kumar, M., Feuillade--Montixi, Q., Bollacker, K., Friedrich, F., Tsang, R., Vidgen, B., Parrish, A., Knotz, C., Presani, E., Bennion, J., Boston, M. F., … Vanschoren, J. (2025). AILUMINATE: Introducing v1.0 of the AI Risk and Reliability Benchmark from MLCommons. In arXiv [cs.CY]. arXiv. http://arxiv.org/abs/2503.05731 Giarmoleo, F. V., Ferrero, I., Rocchi, M., & Pellegrini, M. M. (2024). What ethics can say on artificial intelligence: Insights from a systematic literature review. Business and Society Review. https://doi.org/10.1111/basr.12336 Gipiškis, R., Joaquin, A. S., Chin, Z. S., Regenfuß, A., Gil, A., & Holtman, K. (2024). Risk sources and risk management measures in support of standards for general-purpose AI systems. In arXiv [cs.CY]. arXiv. http://arxiv.org/abs/2410.23472 Google DeepMind. (2024). Frontier Safety Framework. Google DeepMind. https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/introducing-the-frontier-safety-framework/fsf-technical-report.pdf