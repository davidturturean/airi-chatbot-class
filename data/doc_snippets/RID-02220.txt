Repository ID: RID-02220
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: AI Risk Atlas\nRisk Category: Output risks (Fairness)\nRisk Subcategory: Output bias\nAdditional Evidence: "Bias can harm users of the AI models and magnify existing discriminatory behaviors."
domain: Unspecified
entity: 
file_type: ai_risk_entry
intent: 
rid: RID-02220
risk_category: Output risks (Fairness)
row: 2197
scqa_answer: Title: AI Risk Atlas\nRisk Category: Output risks (Fairness)\nRisk Subcategory: Output bias\nAdditional Evidence: "Bias can harm users of the AI models and magnify existing discriminatory behaviors
scqa_complication: Title: AI Risk Atlas\nRisk Category: Output risks (Fairness)\nRisk Subcategory: Output bias\nAdditional Evidence: "Bias can harm users
scqa_confidence: 1.0
scqa_content_type: risk_description
scqa_question: What are the implications of this risk?
scqa_situation: Title: AI Risk Atlas\nRisk Category: Output risks (Fairness)\nRisk Subcategory: Output bias\nAdditional Evidence: "Bias can harm users of the AI models and magnify existing discriminatory behaviors
search_all_fields: AI Risk Atlas Unspecified Output risks (Fairness) Unspecified AI Risk Database v3 ai_risk_entry
search_high_priority: AI Risk Atlas Unspecified Output risks (Fairness)
search_low_priority: AI Risk Database v3 ai_risk_entry
search_medium_priority: Unspecified
sheet: AI Risk Database v3
specific_domain: Unspecified
subdomain: 
timing: 
title: AI Risk Atlas

Content:
Title: AI Risk Atlas\nRisk Category: Output risks (Fairness)\nRisk Subcategory: Output bias\nAdditional Evidence: "Bias can harm users of the AI models and magnify existing discriminatory behaviors."