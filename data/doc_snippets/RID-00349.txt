Repository ID: RID-00349
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: Taxonomy of Risks posed by Language Models\nRisk Category: Risk area 4: Malicious Uses\nRisk Subcategory: Making disinformation cheaper and more effective\nAdditional Evidence: "Disinformation could also be used to create false “majority opinions” by flooding sites with synthetic text, simila...
domain: Unspecified
entity: 
file_type: ai_risk_entry
intent: 
rid: RID-00349
risk_category: Risk area 4: Malicious Uses
row: 326
scqa_answer: Title: Taxonomy of Risks posed by Language Models\nRisk Category: Risk area 4: Malicious Uses\nRisk Subcategory: Making disinformation cheaper and more effective\nAdditional Evidence: "Disinformation could also be used to create false “majority opinions” by flooding sites with synthetic text, similar to bot-driven submissions that undermined a public consultation process in 2017 [74, 89, 111]
scqa_complication: Title: Taxonomy of Risks posed by Language Models\nRisk Category: Risk area 4: Malicious Uses\nRisk Subcategory: Making disinformation cheaper
scqa_confidence: 1.0
scqa_content_type: impact_analysis
scqa_question: What are the implications of this risk?
scqa_situation: Title: Taxonomy of Risks posed by Language Models\nRisk Category: Risk area 4: Malicious Uses\nRisk Subcategory: Making disinformation cheaper and more effective\nAdditional Evidence: "Disinformation could also be used to create false “majority opinions” by flooding sites with synthetic text, similar to bot-driven submissions that undermined a public consultation process in 2017 [74, 89, 111]
search_all_fields: Taxonomy of Risks posed by Language Models Unspecified Risk area 4: Malicious Uses Unspecified AI Risk Database v3 ai_risk_entry
search_high_priority: Taxonomy of Risks posed by Language Models Unspecified Risk area 4: Malicious Uses
search_low_priority: AI Risk Database v3 ai_risk_entry
search_medium_priority: Unspecified
sheet: AI Risk Database v3
specific_domain: Unspecified
subdomain: 
timing: 
title: Taxonomy of Risks posed by Language Models

Content:
Title: Taxonomy of Risks posed by Language Models\nRisk Category: Risk area 4: Malicious Uses\nRisk Subcategory: Making disinformation cheaper and more effective\nAdditional Evidence: "Disinformation could also be used to create false “majority opinions” by flooding sites with synthetic text, similar to bot-driven submissions that undermined a public consultation process in 2017 [74, 89, 111].."