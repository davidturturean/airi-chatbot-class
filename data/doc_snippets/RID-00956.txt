Repository ID: RID-00956
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_confidence: 1.0
search_medium_priority: 1.1 > Unfair discrimination and misrepresentation 1.1 > Unfair discrimination and misrepresentation
search_high_priority: Ethical Issues in the Development of Artificial Intelligence: Recognizing the Risks 1. Discrimination & Toxicity Bias and fairness
content_preview: Title: Ethical Issues in the Development of Artificial Intelligence: Recognizing the Risks\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: Bias and fairness\nDescription: "Participants were concerned that AI systems might perpetuat...
scqa_question: What are the implications of this risk?
entity: 2 - AI
domain: 1. Discrimination & Toxicity
scqa_situation: Title: Ethical Issues in the Development of Artificial Intelligence: Recognizing the Risks\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: Bias and fairness\nDescription: "Participants were concerned that AI systems might perpetuate current prejudices and discrimination, notably in hiring, lending and law enforcem
search_all_fields: Ethical Issues in the Development of Artificial Intelligence: Recognizing the Risks 1. Discrimination & Toxicity Bias and fairness 1.1 > Unfair discrimination and misrepresentation 1.1 > Unfair discrimination and misrepresentation AI Risk Database v3 ai_risk_entry
subdomain: 1.1 > Unfair discrimination and misrepresentation
search_low_priority: AI Risk Database v3 ai_risk_entry
risk_category: Bias and fairness
timing: 3 - Other
specific_domain: 1.1 > Unfair discrimination and misrepresentation
sheet: AI Risk Database v3
scqa_complication: Intelligence: Recognizing the Risks\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: B
intent: 2 - Unintentional
title: Ethical Issues in the Development of Artificial Intelligence: Recognizing the Risks
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_answer: AI judgements may have an unjust impact on specific populations, increasing socioeconomic inequalities and fostering discriminatory practises. Partic
scqa_content_type: impact_analysis
file_type: ai_risk_entry
rid: RID-00956
row: 933

Content:
Title: Ethical Issues in the Development of Artificial Intelligence: Recognizing the Risks\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: Bias and fairness\nDescription: "Participants were concerned that AI systems might perpetuate current prejudices and discrimination, notably in hiring, lending and law enforcement. They stressed the importance of designers creating AI systems that favour justice and avoid biases. The possibility that AI systems may unwittingly perpetuate existing prejudices and discrimination, particularly in sensitive industries such as employment, lending and law enforcement, raises ethical concerns about AI as well as bias and justice issues (Table 1). Because AI systems are trained on historical data, they may inherit and reproduce biases from previous datasets. As a result, AI judgements may have an unjust impact on specific populations, increasing socioeconomic inequalities and fostering discriminatory practises. Participants in the research emphasize the need of AI developers creating systems that promote justice and actively seek to minimise biases."\nEntity: 2 - AI\nIntent: 2 - Unintentional\nTiming: 3 - Other