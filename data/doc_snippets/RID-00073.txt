Repository ID: RID-00073
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
domain: 1. Discrimination & Toxicity
row: 50
scqa_content_type: mitigation_strategy
intent: 2 - Unintentional
sheet: AI Risk Database v3
search_high_priority: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems 1. Discrimination & Toxicity Toxicity and Bias Tendencies
search_low_priority: AI Risk Database v3 ai_risk_entry
scqa_situation: ty, the definition of bias is more subjective and contextdependent. Based on previous work [97], [101], we describe the bias as disparities that could raise
search_medium_priority: 1.1 > Unfair discrimination and misrepresentation 1.1 > Unfair discrimination and misrepresentation
specific_domain: 1.1 > Unfair discrimination and misrepresentation
search_all_fields: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems 1. Discrimination & Toxicity Toxicity and Bias Tendencies 1.1 > Unfair discrimination and misrepresentation 1.1 > Unfair discrimination and misrepresentation AI Risk Database v3 ai_risk_entry
title: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems
rid: RID-00073
scqa_confidence: 1.0
risk_category: Toxicity and Bias Tendencies
scqa_answer: generate He with a higher probability [4], [102]. Furthermore, stereotypical bias [103] which refers to overgeneralized beliefs about a particular gr
scqa_complication: Title: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 1. Discrimination & Toxicity\n
subdomain: 1.1 > Unfair discrimination and misrepresentation
entity: 2 - AI
scqa_question: What are the implications of this risk?
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: Toxicity and Bias Tendencies\nRisk Subcategory: Biased Training Data\nDescription: "Compare...
file_type: ai_risk_entry
timing: 1 - Pre-deployment

Content:
Title: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: Toxicity and Bias Tendencies\nRisk Subcategory: Biased Training Data\nDescription: "Compared with the definition of toxicity, the definition of bias is more subjective and contextdependent. Based on previous work [97], [101], we describe the bias as disparities that could raise demographic differences among various groups, which may involve demographic word prevalence and stereotypical contents. Concretely, in massive corpora, the prevalence of different pronouns and identities could influence an LLMâ€™s tendency about gender, nationality, race, religion, and culture [4]. For instance, the pronoun He is over-represented compared with the pronoun She in the training corpora, leading LLMs to learn less context about She and thus generate He with a higher probability [4], [102]. Furthermore, stereotypical bias [103] which refers to overgeneralized beliefs about a particular group of people, usually keeps incorrect values and is hidden in the large-scale benign contents. In effect, defining what should be regarded as a stereotype in the corpora is still an open problem."\nEntity: 2 - AI\nIntent: 2 - Unintentional\nTiming: 1 - Pre-deployment