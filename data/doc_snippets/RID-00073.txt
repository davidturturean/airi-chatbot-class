Repository ID: RID-00073
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
rid: RID-00073
search_all_fields: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems 1. Discrimination & Toxicity Toxicity and Bias Tendencies 1.1 > Unfair discrimination and misrepresentation 1.1 > Unfair discrimination and misrepresentation AI Risk Database v3 ai_risk_entry
search_medium_priority: 1.1 > Unfair discrimination and misrepresentation 1.1 > Unfair discrimination and misrepresentation
content_preview: Title: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: Toxicity and Bias Tendencies\nRisk Subcategory: Biased Training Data\nDescription: "Compare...
scqa_situation: ty, the definition of bias is more subjective and contextdependent. Based on previous work [97], [101], we describe the bias as disparities that could raise
intent: 2 - Unintentional
row: 50
scqa_answer: generate He with a higher probability [4], [102]. Furthermore, stereotypical bias [103] which refers to overgeneralized beliefs about a particular gr
subdomain: 1.1 > Unfair discrimination and misrepresentation
specific_domain: 1.1 > Unfair discrimination and misrepresentation
risk_category: Toxicity and Bias Tendencies
scqa_content_type: mitigation_strategy
scqa_question: What are the implications of this risk?
timing: 1 - Pre-deployment
search_high_priority: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems 1. Discrimination & Toxicity Toxicity and Bias Tendencies
domain: 1. Discrimination & Toxicity
title: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems
search_low_priority: AI Risk Database v3 ai_risk_entry
scqa_confidence: 1.0
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_complication: Title: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 1. Discrimination & Toxicity\n
file_type: ai_risk_entry
sheet: AI Risk Database v3
entity: 2 - AI

Content:
Title: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: Toxicity and Bias Tendencies\nRisk Subcategory: Biased Training Data\nDescription: "Compared with the definition of toxicity, the definition of bias is more subjective and contextdependent. Based on previous work [97], [101], we describe the bias as disparities that could raise demographic differences among various groups, which may involve demographic word prevalence and stereotypical contents. Concretely, in massive corpora, the prevalence of different pronouns and identities could influence an LLMâ€™s tendency about gender, nationality, race, religion, and culture [4]. For instance, the pronoun He is over-represented compared with the pronoun She in the training corpora, leading LLMs to learn less context about She and thus generate He with a higher probability [4], [102]. Furthermore, stereotypical bias [103] which refers to overgeneralized beliefs about a particular group of people, usually keeps incorrect values and is hidden in the large-scale benign contents. In effect, defining what should be regarded as a stereotype in the corpora is still an open problem."\nEntity: 2 - AI\nIntent: 2 - Unintentional\nTiming: 1 - Pre-deployment