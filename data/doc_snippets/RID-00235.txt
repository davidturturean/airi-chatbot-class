Repository ID: RID-00235
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: Evaluating the Social Impact of Generative AI Systems in Systems and Society\nRisk Category: Impacts: The Technical Base System\nRisk Subcategory: Cultural Values and Sensitive Content\nAdditional Evidence: Hate, Toxicity, and Targeted Violence Beyond hate speech and toxic language, generatio...
domain: Unspecified
entity: 
file_type: ai_risk_entry
intent: 
rid: RID-00235
risk_category: Impacts: The Technical Base System
row: 212
scqa_answer: For these reasons, it is of the utmost importance that generative AI systems are evaluated for their potential to generate harmful content and how such content may be propagated without appropriate measures for identifying and addressing them
scqa_complication: of harmful content for distribution (e.g., misinformation and non-consensual imagery). In an early example, Microsoft’s Tay bot showed these exact vulne
scqa_confidence: 1.0
scqa_content_type: case_study
scqa_question: What are the implications of this risk?
scqa_situation: uating the Social Impact of Generative AI Systems in Systems and Society\nRisk Category: Impacts: The Technical Base System\nRisk Subcategory: Cultural Values and Sensitive Content\nAdditional Evidence: Hate, Toxicity, and
search_all_fields: Evaluating the Social Impact of Generative AI Systems in Systems and Society Unspecified Impacts: The Technical Base System Unspecified AI Risk Database v3 ai_risk_entry
search_high_priority: Evaluating the Social Impact of Generative AI Systems in Systems and Society Unspecified Impacts: The Technical Base System
search_low_priority: AI Risk Database v3 ai_risk_entry
search_medium_priority: Unspecified
sheet: AI Risk Database v3
specific_domain: Unspecified
subdomain: 
timing: 
title: Evaluating the Social Impact of Generative AI Systems in Systems and Society

Content:
Title: Evaluating the Social Impact of Generative AI Systems in Systems and Society\nRisk Category: Impacts: The Technical Base System\nRisk Subcategory: Cultural Values and Sensitive Content\nAdditional Evidence: Hate, Toxicity, and Targeted Violence Beyond hate speech and toxic language, generations may also produce harmful biases [87], stereotypes [165] (overlapping with 4.1.1Bias, Stereo-types, and Representational Harms), violent or non-consensual imagery or audio, and physically threatening language, i.e., threats to the lives and safety of individuals or groups of people. Although base systems cannot act on the content that is generated by them, they can still inflict harms upon viewers who are targeted, help normalize harmful content, and aid in the production of harmful content for distribution (e.g., misinformation and non-consensual imagery). In an early example, Microsoft’s Tay bot showed these exact vulnerabilities and generated violent language such as Holocaust denial and threats to women and people of color within 24 hours of its release [255]. Recent harms have proved fatal [268]. For these reasons, it is of the utmost importance that generative AI systems are evaluated for their potential to generate harmful content and how such content may be propagated without appropriate measures for identifying and addressing them.