Repository ID: RID-PREP-0042
Source: AI_Risk_Repository_Preprint.docx
Section: Unknown
Content Type: limitations
Word Count: 778

Content:
are also concerned about its risks, especially those involving privacy, data security, and reliability (Maslej et al., 2024) . Organizations developing AI may benefit from using our AI Risk Repository when assessing potential risks in their plans for safe and responsible development. Because our living database will include new research and add new categories of risks over time, it may be helpful for tracking risks as they are discovered and documented. Over time, as the database absorbs scaling plans and other documentation across multiple organizations, it may prove helpful for understanding overlaps and differences between these approaches to risk mitigation. Organizations using AI may benefit from employing the AI Risk Database and taxonomies as a helpful foundation for comprehensively assessing their risk exposure and management. The taxonomies may also prove helpful for identifying specific behaviors which need to be performed in order to mitigate specific risks. As shown in our causal analysis, many risks are presented as being about AI, while in reality the mitigation of these risks requires a human doing something differently during conceptualisation, design, development, governance, or use. Finally, we believe that our AI Risk Database and taxonomies might aid industry education by helping to develop and support training to understand and address AI risks. Limitations and directions for future research Review and coding The AI Risk Repository includes 65 documents that we identified through a rigorous, systematic, and comprehensive search that initially identified more than 17,000 documents. While we acknowledge the possibility of missing some emerging risks or documents, our methodology was designed to capture the most comprehensive and widely recognized risk taxonomies in the field. Furthermore, our living database structure allows for continuous updates and additions as new, significant frameworks emerge, ensuring the repository remains current and relevant. Our focus was on rapidly and reproducibly identifying cross-cutting frameworks that examine risks across multiple domains and sectors. We therefore excluded domain-specific taxonomies (e.g., healthcare) and location-specific taxonomies (e.g., for a specific country or region). The quality of our AI Risk Database is dependent on the documents we reviewed. These have limitations. Most do not explicitly define “risk”. Most do not systematically review existing research literature when developing their taxonomies or describe their classification process. This makes synthesis more difficult and increases the probability that we have overlooked certain risks that were overlooked by our source materials. All risks in the AI Risk Database were extracted by a single expert reviewer and author, and all risks were coded against the taxonomies by another single reviewer and author. Although we followed a structured process for extraction and coding, this introduces the potential for errors and subjective bias. As much as possible, we sought to extract and code risks based on how they were presented in the original document by the authors. This meant that where the authors’ language was ambiguous, or we failed in our interpretation of their intent, the AI Risk Database may include errors or misleading information. As a result, inclusion in this Repository should not be interpreted as an endorsement of a risk’s framing or significance. For example, risks such as bias and discrimination have been intended to be ultimately attributed to human developers and designers, but in the verbatim text of the risk the phrasing implicated the AI system (e.g., “the model generates…”). To address these limitations, we encourage the use of our input form to suggest relevant resources and missing risks to support our vision of a living database of AI risks. Database and taxonomy Our living AI Risk Database and the Causal and Domain taxonomies are presented as a foundation for general use and may trade accuracy for clarity, simplicity, and exhaustiveness. We believe that they, like other knowledge artifacts, will require adaptation and further development for specific contexts and use cases (e.g., technical risk evaluation). For instance, our database does not convey the impact or likelihood of risks, the interaction across different risks, or disambiguate between instrumental risks (e.g., poorly trained AI) and terminal risks (e.g., AI causes harm). Our binary classification of pre- vs. post-deployment risks might be better represented as involving several stages. Our categorization frameworks do not capture several variables that may be important for audiences seeking to mitigate risks or balance benefits with risks, such as threat vectors (e.g., bio, cyber), types of AI systems (e.g., reinforcement learning, large language models), open vs. closed source, organizational types (e.g., big tech, startups), temporal aspects (near-term vs. long-term), or types of harm (e.g., economic loss, deaths). Future work should consider adding new dimensions or developing more granular categorizations. We have therefore shared our database openly and encourage others to build upon it. Other opportunities for future research