Repository ID: RID-02195
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: AI Risk Atlas\nDomain: 5. Human-Computer Interaction\nSub-domain: 5.1 > Overreliance and unsafe use\nRisk Category: Output risks (Value alignment)\nRisk Subcategory: Over- or under-reliance\nDescription: "In AI-assisted decision-making tasks, reliance measures how much a person trusts (and po...
domain: 5. Human-Computer Interaction
entity: 1 - Human
file_type: ai_risk_entry
intent: 2 - Unintentional
rid: RID-02195
risk_category: Output risks (Value alignment)
row: 2172
scqa_answer: "\nEntity: 1 - Human\nIntent: 2 - Unintentional\nTiming: 2 - Post-deployment
scqa_complication: erson doesn’t trust the model but should."\nEntity: 1 - Human\nIntent: 2 - Unintentional\nTiming: 2 - Post-deployment
scqa_confidence: 1.0
scqa_content_type: risk_description
scqa_question: What are the implications of this risk?
scqa_situation: Title: AI Risk Atlas\nDomain: 5
search_all_fields: AI Risk Atlas 5. Human-Computer Interaction Output risks (Value alignment) 5.1 > Overreliance and unsafe use 5.1 > Overreliance and unsafe use AI Risk Database v3 ai_risk_entry
search_high_priority: AI Risk Atlas 5. Human-Computer Interaction Output risks (Value alignment)
search_low_priority: AI Risk Database v3 ai_risk_entry
search_medium_priority: 5.1 > Overreliance and unsafe use 5.1 > Overreliance and unsafe use
sheet: AI Risk Database v3
specific_domain: 5.1 > Overreliance and unsafe use
subdomain: 5.1 > Overreliance and unsafe use
timing: 2 - Post-deployment
title: AI Risk Atlas

Content:
Title: AI Risk Atlas\nDomain: 5. Human-Computer Interaction\nSub-domain: 5.1 > Overreliance and unsafe use\nRisk Category: Output risks (Value alignment)\nRisk Subcategory: Over- or under-reliance\nDescription: "In AI-assisted decision-making tasks, reliance measures how much a person trusts (and potentially acts on) a model’s output. Over-reliance occurs when a person puts too much trust in a model, accepting a model’s output when the model’s output is likely incorrect. Under-reliance is the opposite, where the person doesn’t trust the model but should."\nEntity: 1 - Human\nIntent: 2 - Unintentional\nTiming: 2 - Post-deployment