Repository ID: RID-PREP-0028
Source: AI_Risk_Repository_Preprint.docx
Section: Causal Taxonomy
Content Type: limitations
Word Count: 628

Content:
Developing, proposing, debating, and implementing new regulations often involves multiple stakeholders, including government bodies, industry experts, and consultations with the public. The mismatch between the speed of AI advancements and their regulation may result in immature regulations that overlook important aspects of AI governance (Wirtz et al., 2022). The “great scope and ubiquity” of AI increases the difficulty of comprehensive governance (Wirtz et al., 2022). At present, many emerging aspects of AI-generated content are not explicitly addressed in copyright laws (Nah et al., 2023). Regulatory lags such as this could become increasingly dangerous as AI systems develop more harmful capabilities. A third challenge for effective governance is an inability to influence AI developers and deployers to take safe actions. Frequently, this inability is driven by an asymmetry of information between technology companies and regulators (Nah et al., 2023). Technology companies often have far better knowledge about the capabilities, functioning, and potential uses of their AI systems; they possess both the technical expertise and the proprietary data that inform AI development. Without access to this knowledge, regulators can find it difficult to craft targeted rules that address the specific challenges posed by AI. 6.6 Environmental harm. Generative models, especially those that use deep learning techniques, require vast amounts of resources to train, test, and deploy (Hagendorff, 2024; Solaiman et al., 2023). Training a model can take days or weeks. This process requires powerful processors that consume large amounts of electricity and produce significant greenhouse emissions (Electronic Privacy Information Centre, 2023; Hagendorff, 2024; Saghiri et al., 2022; Solaiman et al., 2023; Weidinger et al., 2021, 2022). The hardware that runs AI models – primarily GPUs – often contains rare metals (e.g., nickel, cobalt, and lithium) that are costly and environmentally taxing to collect and process (Hagendorff, 2024; Paes et al., 2023; Shelby et al., 2023). Data centers that house models generate significant heat and require substantial water and energy to cool (Weidinger et al., 2022). Secondary environmental impacts include emissions from AI-enabled applications (Weidinger et al., 2022). The resource requirements of AIs can impose significant costs on the natural environment (Stahl & Eke, 2024; Weidinger et al., 2023), as they are often acquired and used in ways that are unsustainable (Hagendorff, 2024) (i.e., produce significant carbon emissions), deplete resources, and damage built environments (Shelby et al., 2023). Domain 7: AI system safety, failures & limitations 7.1 AI pursuing its own goals in conflict with human goals or values. Continued massive investment in AI research and development raises the possibility that AI systems could eventually rival or surpass human intelligence. AIs could cause permanent and severe harm when the objectives of human or superhuman-level AI are misaligned with human values and goals, and if they evade our control (Hagendorff, 2024; Yampolskiy, 2016). The literature has identified several technical challenges that may impede robust alignment, such as reward hacking, reward tampering, proxy-gaming, goal misgeneralisation, or goal drift (Gabriel et al., 2024; Hagendorff, 2024; Hendrycks et al., 2023; Hendrycks & Mazeika, 2022; Hogenhout, 2021; Ji et al., 2023). The literature has also identified a range of harmful behaviors that AIs may exhibit if these misalignment challenges cannot be solved and if systems reach a certain level of advancement. For instance, misaligned AIs may resist human attempts to control or shut them down (Gabriel et al., 2024; Hagendorff, 2024; Infocomm Media Development Authority, 2023; Saghiri et al., 2022; Stahl & Eke, 2024; Weidinger et al., 2023; Wirtz et al., 2022). In many cases, gaining more control or power (e.g., money, energy, resources) is an effective way for an AI to optimize its objectives (Gabriel et al., 2024; Hagendorff, 2024; Hendrycks & Mazeika, 2022; Ji et al., 2023; Wirtz et al., 2022). Absent strong behavioral constraints, a sufficiently advanced AI may act upon these drives.