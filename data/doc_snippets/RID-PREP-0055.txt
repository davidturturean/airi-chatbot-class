Repository ID: RID-PREP-0055
Source: AI_Risk_Repository_Preprint.docx
Section: Unknown
Content Type: comparative_analysis
Word Count: 770

Content:
Sherman, E., & Eisenberg, I. (2024). AI Risk Profiles: A Standards Proposal for Pre-deployment AI Risk Disclosures. Proceedings of the AAAI Conference on Artificial Intelligence, 38(21), 23047–23052. https://doi.org/10.1609/aaai.v38i21.30348 Shevlane, T., Farquhar, S., Garfinkel, B., Phuong, M., Whittlestone, J., Leung, J., Kokotajlo, D., Marchal, N., Anderljung, M., Kolt, N., Ho, L., Siddarth, D., Avin, S., Hawkins, W., Kim, B., Gabriel, I., Bolina, V., Clark, J., Bengio, Y., … Dafoe, A. (2023). Model evaluation for extreme risks. In arXiv [cs.AI]. arXiv. http://arxiv.org/abs/2305.15324 Sohn, R. (2022, April). AI Drug Discovery Systems Might Be Repurposed to Make Chemical Weapons, Researchers Warn. Scientific American. https://www.scientificamerican.com/article/ai-drug-discovery-systems-might-be-repurposed-to-make-chemical-weapons-researchers-warn/ Solaiman, I., Talat, Z., Agnew, W., Ahmad, L., Baker, D., Blodgett, S. L., Daumé, H., III, Dodge, J., Evans, E., Hooker, S., Jernite, Y., Luccioni, A. S., Lusoli, A., Mitchell, M., Newman, J., Png, M.-T., Strait, A., & Vassilev, A. (2023). Evaluating the Social Impact of Generative AI Systems in Systems and Society. In arXiv [cs.CY]. arXiv. http://arxiv.org/abs/2306.05949 Sovacool, B. K., & Hess, D. J. (2017). Ordering theories: Typologies and conceptual frameworks for sociotechnical change. Social Studies of Science, 47(5), 703–750. https://doi.org/10.1177/0306312717709363 Stahl, B. C., & Eke, D. (2024). The ethics of ChatGPT – Exploring the ethical issues of an emerging technology. International Journal of Information Management, 74(102700), 102700. https://doi.org/10.1016/j.ijinfomgt.2023.102700 Steimers, A., & Schneider, M. (2022). Sources of Risk of AI Systems. International Journal of Environmental Research and Public Health, 19(6). https://doi.org/10.3390/ijerph19063641 Sun, H., Zhang, Z., Deng, J., Cheng, J., & Huang, M. (2023). Safety Assessment of Chinese Large Language Models. In arXiv [cs.CL]. arXiv. http://arxiv.org/abs/2304.10436 Tan, S., Taeihagh, A., & Baxter, K. (2022). The Risks of Machine Learning Systems. In arXiv [cs.CY]. arXiv. http://arxiv.org/abs/2204.09852 Teixeira, S., Rodrigues, J., Veloso, B., & Gama, J. (2022). An Exploratory Diagnosis of Artificial Intelligence Risks for a Responsible Governance. Proceedings of the 15th International Conference on Theory and Practice of Electronic Governance, 25–31. https://doi.org/10.1145/3560107.3560298 Thomas, J., & Harden, A. (2008). Methods for the thematic synthesis of qualitative research in systematic reviews. BMC Medical Research Methodology, 8, 45. https://doi.org/10.1186/1471-2288-8-45 Tricco, A. C., Langlois, E. V., & Straus, S. E. (2017). Rapid reviews to strengthen health policy and systems: a practical guide. World Health Organization. https://ahpsr.who.int/publications/i/item/2017-08-10-rapid-reviews-to-strengthen-health-policy-and-systems-a-practical-guide UK Department for Science, Innovation and Technology. (2023a). A pro-innovation approach to AI regulation. https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper UK Department for Science, Innovation and Technology. (2023b). The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023. https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023 Uuk, R., Gutierrez, C. I., Guppy, D., Lauwaert, L., Kasirzadeh, A., Velasco, L., Slattery, P., & Prunkl, C. (2025). A taxonomy of systemic risks from general-purpose AI. In arXiv [cs.CY]. arXiv. https://doi.org/10.2139/ssrn.5030173 van de Schoot, R., de Bruin, J., Schram, R., Zahedi, P., de Boer, J., Weijdema, F., Kramer, B., Huijts, M., Hoogerwerf, M., Ferdinands, G., Harkema, A., Willemsen, J., Ma, Y., Fang, Q., Hindriks, S., Tummers, L., & Oberski, D. L. (2021). An open source machine learning framework for efficient and transparent systematic reviews. Nature Machine Intelligence, 3(2), 125–133. https://doi.org/10.1038/s42256-020-00287-7 Vidgen, B., Agrawal, A., Ahmed, A. M., Akinwande, V., Al-Nuaimi, N., Alfaraj, N., Alhajjar, E., Aroyo, L., Bavalatti, T., Blili-Hamelin, B., Bollacker, K., Bomassani, R., Boston, M. F., Campos, S., Chakra, K., Chen, C., Coleman, C., Coudert, Z. D., Derczynski, L., … Vanschoren, J. (2024). Introducing v0.5 of the AI Safety Benchmark from MLCommons. In arXiv [cs.CL]. arXiv. http://arxiv.org/abs/2404.12241 Weidinger, L., Mellor, J., Rauh, M., Griffin, C., Uesato, J., Huang, P.-S., Cheng, M., Glaese, M., Balle, B., Kasirzadeh, A., Kenton, Z., Brown, S., Hawkins, W., Stepleton, T., Biles, C., Birhane, A., Haas, J., Rimell, L., Hendricks, L. A., … Gabriel, I. (2021). Ethical and social risks of harm from Language Models. In arXiv [cs.CL]. arXiv. http://arxiv.org/abs/2112.04359 Weidinger, L., Rauh, M., Marchal, N., Manzini, A., Hendricks, L. A., Mateos-Garcia, J., Bergman, S., Kay, J., Griffin, C., Bariach, B., Gabriel, I., Rieser, V., & Isaac, W. (2023). Sociotechnical Safety Evaluation of Generative AI Systems. In arXiv [cs.AI]. arXiv. http://arxiv.org/abs/2310.11986 Weidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., Glaese, A., Cheng, M., Balle, B., Kasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W., Stepleton, T., Birhane, A., Hendricks, L. A., Rimell, L., Isaac, W., … Gabriel, I. (2022). Taxonomy of Risks posed by Language Models. Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency, 214–229. https://doi.org/10.1145/3531146.3533088 Wilczynski, N. L., Haynes, R. B., & Hedges Team. (2003). Developing optimal search strategies for detecting clinically sound causation studies in MEDLINE. AMIA ... Annual Symposium Proceedings / AMIA Symposium. AMIA Symposium, 2003, 719–723. https://www.ncbi.nlm.nih.gov/pubmed/14728267 Wirtz, B. W., Weyerer, J. C., & Kehl, I. (2022). Governance of artificial intelligence: A risk and guideline-based integrative framework. Government Information Quarterly, 39(4), 101685. https://doi.org/10.1016/j.giq.2022.101685