Repository ID: RID-01388
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: AGI Safety Literature Review\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.3 > Lack of capability or robustness\nRisk Category: Safe learning\nDescription: "AGIs should avoid making fatal mistakes during the learning phase.
Subproblems include safe exploration and distr...
domain: 7. AI System Safety, Failures, & Limitations
entity: 2 - AI
file_type: ai_risk_entry
intent: 2 - Unintentional
rid: RID-01388
risk_category: Safe learning
row: 1365
scqa_answer: "\nEntity: 2 - AI\nIntent: 2 - Unintentional\nTiming: 1 - Pre-deployment
scqa_complication: de safe exploration and distributional shift (DeepMind, OpenAI), and continual learning (Berkeley)."\nEntity: 2 - AI\nIntent: 2 - Unintentional\nTiming:
scqa_confidence: 1.0
scqa_content_type: risk_description
scqa_question: What are the implications of this risk?
scqa_situation: Title: AGI Safety Literature Review\nDomain: 7
search_all_fields: AGI Safety Literature Review 7. AI System Safety, Failures, & Limitations Safe learning 7.3 > Lack of capability or robustness 7.3 > Lack of capability or robustness AI Risk Database v3 ai_risk_entry
search_high_priority: AGI Safety Literature Review 7. AI System Safety, Failures, & Limitations Safe learning
search_low_priority: AI Risk Database v3 ai_risk_entry
search_medium_priority: 7.3 > Lack of capability or robustness 7.3 > Lack of capability or robustness
sheet: AI Risk Database v3
specific_domain: 7.3 > Lack of capability or robustness
subdomain: 7.3 > Lack of capability or robustness
timing: 1 - Pre-deployment
title: AGI Safety Literature Review
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx

Content:
Title: AGI Safety Literature Review\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.3 > Lack of capability or robustness\nRisk Category: Safe learning\nDescription: "AGIs should avoid making fatal mistakes during the learning phase.
Subproblems include safe exploration and distributional shift (DeepMind, OpenAI), and continual learning (Berkeley)."\nEntity: 2 - AI\nIntent: 2 - Unintentional\nTiming: 1 - Pre-deployment