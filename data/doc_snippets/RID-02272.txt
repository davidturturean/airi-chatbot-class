Repository ID: RID-02272
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
sheet: AI Risk Database v3
search_medium_priority: 3.1 > False or misleading information
scqa_question: What are the implications of this risk?
rid: RID-02272
scqa_complication: made-up academic references. However, as ChatGPT-type tools become available to the general population, the scale of the problem may increase dramatically. F
search_all_fields: AI Risk Domain: 3.1 > False or misleading information 3.1 > False or misleading information 3.1 > False or misleading information AI Risk Database v3 ai_risk_domain_summary
scqa_confidence: 1.0
scqa_content_type: case_study
file_type: ai_risk_domain_summary
domain: 3.1 > False or misleading information
entry_count: 41
is_summary: True
scqa_situation: 3.1 > False or misleading information\n\nThis domain contains 41 risk entries from the AI Risk Repository:\n\nRisk Entry 1:\nTitle: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 3. Misinformation\nSub-domain: 3.1 > False or misleading information\nRisk Category: Untru
specific_domain: 3.1 > False or misleading information
search_high_priority: AI Risk Domain: 3.1 > False or misleading information 3.1 > False or misleading information
summary_type: domain_aggregation
content_preview: AI Risk Domain: 3.1 > False or misleading information\n\nThis domain contains 41 risk entries from the AI Risk Repository:\n\nRisk Entry 1:\nTitle: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 3. Misinformation\nSub-domain: 3.1 > False or misleading i...
title: AI Risk Domain: 3.1 > False or misleading information
search_low_priority: AI Risk Database v3 ai_risk_domain_summary
scqa_answer: the gap between knowledge involved in an input prompt and knowledge embedded in the LLMs can lead to hallucinations"\nEntity: 2 - AI\nIntent: 2 - Uni

Content:
Entry 7:\nTitle: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 3. Misinformation\nSub-domain: 3.1 > False or misleading information\nRisk Category: Hallucinations\nRisk Subcategory: Defective Decoding Process\nDescription: In general, LLMs employ the Transformer architecture [32] and generate content in an autoregressive manner, where the prediction of the next token is conditioned on the previously generated token sequence. Such a scheme could accumulate errors [105]. Besides, during the decoding process, top-p sampling [28] and top-k sampling [27] are widely adopted to enhance the diversity of the generated content. Nevertheless, these sampling strategies can introduce “randomness” [113], [136], thereby increasing the potential of hallucinations"\nEntity: 2 - AI\nIntent: 2 - Unintentional\nTiming: 1 - Pre-deployment\n\nRisk Entry 8:\nTitle: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 3.