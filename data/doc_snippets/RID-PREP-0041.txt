Repository ID: RID-PREP-0041
Source: AI_Risk_Repository_Preprint.docx
Section: Unknown
Content Type: general
Word Count: 720

Content:
common language and criteria for discussing AI risks. For example, the EU-US Trade and Technology Council is developing a shared repository of metrics and methodologies for measuring AI trustworthiness, risk management methods, and related tools, and the AI Risk Repository could support this and similar efforts (European Commission and the United States Trade and Technology Council, 2022). Beyond the above examples, the AI Risk Repository may also be valuable to policymakers in need of a comprehensive, up-to-date database of AI risks for their work on risk prioritization, risk trend tracking, the development of AI risk training programs, and more. Auditors Formal evaluations of AI systems, known as audits, are gaining interest as a governance mechanism to assess and mitigate risks. However, for audits to offer a meaningful governance mechanism, there must be auditing regimes that ensure risky systems are comprehensively and systematically assessed for potential harms. Who decides what risks should be considered within an audit’s scope? And who decides when an AI system has been shown to pose a specific risk? Recently, some AI risk-management frameworks have emerged which are limited in scope to a narrow set of risk types (Anthropic, 2023; Google DeepMind, 2024). Meanwhile, there are currently no widely accepted frameworks for determining when an AI system poses specific risks. When risks are defined vaguely, it is possible for disagreements to arise about whether a system poses one. If audits are to be conducted in a way that is not frivolous or perfunctory, there needs to be objective and legally tenable standards for deciding when a system is determined to pose a risk (Costanza-Chock et al., 2022). Our framework does not offer a list of definitions of risks or criteria for when a system should be determined to pose them. However, it offers a comprehensive and shared understanding of risks from AI systems which is a prerequisite for this. We therefore hope that our Repository of risks can be useful for policymakers, auditors, and industry for formulating comprehensive standards for audits. Academics Academic researchers are increasingly grappling with the risks from artificial intelligence and how to address them. However, as our analysis has shown, the intense and urgent examination of risks from AI has led to a lack of shared understanding of those risks. Academics can use the taxonomy to synthesize information about AI risks across studies, sectors, sources, or disciplines. For example, the taxonomies could be used to explore differences in how government bodies or industry sectors are responding to specific causes or domains of risk from AI. The AI Risk Database provides a starting point for the development of more sophisticated classifications and research tools, similar to “The O*NET Content Model” in economics (Handel, 2016; Horvát & Webb, 2020) or the “International Classification of Diseases” in medicine (Brand et al., 2020). We hope that academic researchers will use the database and taxonomies to assist them in identifying gaps in current knowledge and direct their efforts toward filling these gaps. For instance, researchers may find it helpful to use the AI Risk Database to find existing relevant research or to contextualize their specific research interests within a wider landscape of AI risk scholarship. Researchers can directly contribute to our living database by using this form to suggest additional documents or categories of AI risks, help to code new content, or update our taxonomies. Finally, we believe that our AI Risk Database and taxonomies can assist education and training about AI and its risks by assisting students and professionals to understand causal factors and domains of AI risks. They can also develop a deeper understanding of AI risks through investigation of the database and the included documents. Industry Many organizations who are designing, deploying, or using AI are also concerned about its risks, especially those involving privacy, data security, and reliability (Maslej et al., 2024) . Organizations developing AI may benefit from using our AI Risk Repository when assessing potential risks in their plans for safe and responsible development. Because our living database will include new research and add new categories of risks over time, it may be helpful for tracking risks as they are discovered and documented. Over time, as the database absorbs scaling plans and other documentation across multiple organizations, it may prove helpful for understanding overlaps and differences between these approaches to risk mitigation.