Repository ID: RID-PREP-0037
Source: AI_Risk_Repository_Preprint.docx
Section: Domain Taxonomy
Content Type: limitations
Word Count: 783

Content:
interaction 5.1 Overreliance and unsafe use 45% 22% 33% 12% 61% 27% 94% 6% 5.2 Loss of human agency and autonomy 29% 26% 45% 16% 39% 45% 74% 26% 6 Socioeconomic & environmental harms 6.1 Power centralization and unfair distribution of benefits 72% 4% 23% 38% 28% 34% 4% 51% 45% 6.2 Increased inequality and decline in employment quality 52% 32% 16% 41% 11% 48% 11% 77% 11% 6.3 Economic and cultural devaluation of human effort 50% 37% 13% 37% 20% 43% 13% 60% 27% 6.4 Competitive dynamics 68% 11% 21% 42% 42% 16% 21% 26% 53% 6.5 Governance failure 57% 18% 25% 4% 54% 43% 41% 27% 32% 6.6 Environmental harm 31% 48% 19% 10% 69% 19% 15% 42% 42% 7 AI system safety, failures & limitations 7.1 AI pursuing its own goals in conflict with human goals or values 9% 72% 18% 50% 13% 36% 19% 31% 49% 7.2 AI possessing dangerous capabilities 7% 91% 2% 69% 15% 17% 9% 44% 46% 7.3 Lack of capability or robustness 19% 66% 15% 5% 70% 24% 24% 50% 25% 7.4 Lack of transparency or interpretability 20% 53% 28% 55% 45% 15% 53% 33% 7.5 AI welfare and rights 67% 33% 33% 67% 33% 67% 7.6 Multi-agent risks 7% 70% 24% 28% 46% 26% 2% 83% 15% Note. The most common level of each causal factor is highlighted for each subdomain. Entity Risks presented as occurring due to a decision or action made by an AI system (i.e., AI as a causal Entity) were most common in the Discrimination & toxicity, Misinformation, and AI system safety, failures & limitations domains. Some specific subdomains were presented with very high specificity, for example, AI was presented as the causal Entity for 90% of the risks coded as 3.1 False or misleading information. In contrast, for 2.1 Compromise of privacy by obtaining, leaking or correctly inferring sensitive information, AI was presented as the most common causal Entity for only 58% of the risks, indicating less consistency or coherence in how who is responsible for privacy risks are discussed in the literature. In other domains and subdomains, risks were presented as occurring due to a decision or action made by humans (i.e., Humans as a causal Entity). Humans were presented as the most common Entity for all the subdomains in the Malicious actors & misuse domain, and for all subdomains in the Socioeconomic and environmental domain except for 6.6 Environmental harm. As observed with AI as a causal Entity, risks were sometimes presented as overwhelmingly attributable to Human decisions or actions (e.g., 6.1 Power centralization and unfair distribution of benefits, 72%; 4.3 Fraud, scams, and targeted manipulation, 79%; Cyberattacks, weapon development or use, and mass harm, 76%. Intent Risks attributed to an expected outcome from pursuing a goal (i.e., Intentional Intent) were overwhelmingly presented in the Malicious actors & misuse domain. Risks arising from Intentional decisions or actions were also more common in 2.1 AI system security vulnerabilities and attacks, 73% and 7.2 AI possessing dangerous capabilities, 69%. This suggests a significant awareness and concern over the purposeful manipulation of AI technologies to cause harm or gain advantage. In contrast, some domains and subdomains include risks presented as due to an unexpected outcome from pursuing a goal (i.e., Unintentional intent), with both 1.1 Unfair discrimination and misrepresentation and 1.3 Unequal performance across groups presented as overwhelmingly due to Unintentional intent. Intent was frequently specified ambiguously or missing from descriptions of risk, which is demonstrated by a lack of specificity in several subdomains. For example, 6.1 Power centralization and unfair distribution of benefits was most commonly presented as Intentional (38%), but a significant minority of documents presented this risk as Unintentional (28%) or Other (34%). Timing Most risks in the database are presented as occurring after the AI model has been trained and deployed (i.e., Post-deployment Timing), and only subdomain 6.5 Governance failure was presented as primarily occurring during Pre-deployment. Some subdomains of risk with multiple or ambiguous timings include 2.2 AI system security vulnerabilities and attacks, 6.6 Environmental Harm, 7.1 AI pursuing its own goals in conflict with human goals or values, 7.2 AI possessing dangerous capabilities, 7.5 AI welfare and rights, 6.4 Competitive dynamics. This implies that these domains of risk may emerge or occur multiple times during development and deployment. Entity x Intent causal factors by each domain of AI risk As a preliminary investigation and demonstration, we explore here how multiple variables from the Causal Taxonomy can be combined to provide additional insights about risks in the Domain Taxonomy. This investigation is intended to illustrate how more in-depth assessment is possible using the AI Risk Database by selecting and combining causal factors and risk domains.