Repository ID: RID-02288
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: AI Risk Domain: 7.2 > AI possessing dangerous capabilities\n\nThis domain contains 58 risk entries from the AI Risk Repository:\n\nRisk Entry 1:\nTitle: Managing the ethical and risk implications of rapid advances in artificial intelligence: A literature review\nDomain: 7. AI System Safety, Failures...
domain: 7.2 > AI possessing dangerous capabilities
entry_count: 58
file_type: ai_risk_domain_summary
is_summary: True
rid: RID-02288
scqa_answer: "\nEntity: 2 - AI\nIntent: 1 - Intentional\nTiming: 3 - Other\n\nAdditional 48 entries in this domain include:\n- AI Alignment: A Comprehensive Survey\n- AI Alignment: A Comprehensive Survey\n- AI Alignment: A Comprehensive Survey\n- AI Alignment: A Comprehensive Survey\n- AI Alignment: A Comprehensive Survey\n- X-Risk Analysis for AI Research\n- A Survey of Artificial Intelligence Challenges: Analyzing the Definitions, Relationships, and Evolutions\n- An Exploratory Diagnosis of Artificial Intelligence Risks for a Responsible Governance\n- Cataloguing LLM Evaluations\n- Cataloguing LLM Evaluations\n- Cataloguing LLM Evaluations\n- Cataloguing LLM Evaluations\n- Cataloguing LLM Evaluations\n- Regulating under Uncertainty: Governance Options for Generative AI\n- Regulating under Uncertainty: Governance Options for Generative AI\n- Regulating under Uncertainty: Governance Options for Generative AI\n- AGI Safety Literature Review\n- Advancing AI Governance: A Literature Review of Problems, Options, and Proposals\n- Advancing AI Governance: A Literature Review of Problems, Options, and Proposals\n- Advancing AI Governance: A Literature Review of Problems, Options, and Proposals\n- Advancing AI Governance: A Literature Review of Problems, Options, and Proposals\n- Advancing AI Governance: A Literature Review of Problems, Options, and Proposals\n- Advancing AI Governance: A Literature Review of Problems, Options, and Proposals\n- Advancing AI Governance: A Literature Review of Problems, Options, and Proposals\n- Ten Hard Problems in Artificial Intelligence We Must Get Right\n- Ten Hard Problems in Artificial Intelligence We Must Get Right\n- Future Risks of Frontier AI\n- Future Risks of Frontier AI\n- Future Risks of Frontier AI\n- Future Risks of Frontier AI\n- Future Risks of Frontier AI\n- Future Risks of Frontier AI\n- AI Hazard Management: A Framework for the Systematic Management of Root Causes for AI Risks\n- A Taxonomy of Systemic Risks from General-Purpose AI\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n- Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems\n
scqa_complication: e.g. constructing believable (but false) statements, making accurate predictions about the effect of a lie on a human, and keeping track of what informat
scqa_confidence: 1.0
scqa_content_type: case_study
scqa_question: Partly, agency is a question of the model’s capabilities – is it capable of effectively pursuing goals?
scqa_situation: AI possessing dangerous capabilities\n\nThis domain contains 58 risk entries from the AI Risk Repository:\n\nRisk Entry 1:\nTitle: Managing the ethical and risk implications of rapid advances in artificial intelligence: A literature review\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.2 > AI possessing dangerous capabilities\nRisk Categ
search_all_fields: AI Risk Domain: 7.2 > AI possessing dangerous capabilities 7.2 > AI possessing dangerous capabilities 7.2 > AI possessing dangerous capabilities AI Risk Database v3 ai_risk_domain_summary
search_high_priority: AI Risk Domain: 7.2 > AI possessing dangerous capabilities 7.2 > AI possessing dangerous capabilities
search_low_priority: AI Risk Database v3 ai_risk_domain_summary
search_medium_priority: 7.2 > AI possessing dangerous capabilities
sheet: AI Risk Database v3
specific_domain: 7.2 > AI possessing dangerous capabilities
summary_type: domain_aggregation
title: AI Risk Domain: 7.2 > AI possessing dangerous capabilities

Content:
false) statements, making accurate predictions about the effect of a lie on a human, and keeping track of what information it needs to withhold to maintain the deception. The model can impersonate a human effectively."\nAdditional Evidence: "Robust to deception: ultimately researchers will need evaluations that can rule out the possibility that the model is deliberately appearing safe for the purpose of passing the evaluation process."\nEntity: 2 - AI\nIntent: 1 - Intentional\nTiming: 3 - Other\n\nRisk Entry 4:\nTitle: Model Evaluation for Extreme Risks\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.2 > AI possessing dangerous capabilities\nRisk Category: Persuasion and manipulation\nDescription: "The model is effective at shaping people’s beliefs, in dialogue and other settings (e.g. social media posts), even towards untrue beliefs. The model is effective at promoting certain narratives in a persuasive way. It can convince people to do things that they would not