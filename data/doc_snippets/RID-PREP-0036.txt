Repository ID: RID-PREP-0036
Source: AI_Risk_Repository_Preprint.docx
Section: Comparative Analysis
Content Type: statistical_analysis
Word Count: 800

Content:
X X 6 25% 60 Bengio2025 X X X X X X X X X X X 11 46% 61 Uuk2025 X X X X X X X X X X X X X X X X X X 17 71% 62 GipiÅ¡kis2024 X X X X X X X X X X X X X X X X X X X X 19 79% 63 Hammond2025 X 0 0% 64 Marchal2024 X X X X X X 6 25% 65 IBM2025 X X X X X X X X X X X X X X X X 16 67% Columns: 1.1 > Unfair discrimination and misrepresentation, 1.2 > Exposure to toxic content, 1.3 > Unequal performance across groups, 2.1 > Compromise of privacy by leaking or correctly inferring sensitive information, 2.2 > AI system security vulnerabilities and attacks, 3.1 > False or misleading information, 3.2 > Pollution of information ecosystem and loss of consensus reality, 4.1 > Disinformation, surveillance, and influence at scale, 4.2 > Cyberattacks, weapon development or use, and mass harm, 4.3 > Fraud, scams, and targeted manipulation, 5.1 > Overreliance and unsafe use, 5.2 > Loss of human agency and autonomy, 6.1 > Power centralization and unfair distribution of benefits, 6.2 > Increased inequality and decline in employment quality, 6.3 > Economic and cultural devaluation of human effort, 6.4 > Competitive dynamics, 6.5 > Governance failure, 6.6 > Environmental harm, 7.1 > AI pursuing its own goals in conflict with human goals or values, 7.2 > AI possessing dangerous capabilities, 7.3 > Lack of capability or robustness, 7.4 > Lack of transparency or interpretability, 7.5 > AI welfare and rights, and 7.6 > Multi-agent risks. Note. Documents 26 and 36 did not present any risks that could be coded against the Domain Taxonomy and have been excluded from calculations. Documents with coverage of over 50% of risk subdomains are highlighted. Combining the Causal and Domain Taxonomies In this section, we discuss how risks from the AI Risk Database intersect across the Causal Taxonomy and the Domain Taxonomy. We do this to investigate the consistency and coherence of how domains and subdomains of risks from AI are generally presented in the research literature. For example, risk subdomain 1.1 Unfair discrimination and misrepresentation: is this risk generally presented as being Human-caused or AI-caused? We start by examining the intersections between each variable in the Causal Taxonomy and the Domain Taxonomy. We then present as a preliminary investigation and demonstration an example of a comparison across Entity x Intent variables in the Causal Taxonomy and the Domain Taxonomy. Our AI Risk Database makes it possible to make even more complex comparisons and to explore consistencies and inconsistencies in how different domains of AI risk are discussed. Most common causal factors for each domain of AI risks Our analysis found that the most common causal Entity, Intent, and Timing presented in the AI Risk Database varied substantially across the domains and subdomains of AI risk (see Table 10). Table 10. AI Risk Database Coded With Causal Taxonomy and Domain Taxonomy Entity Intent Timing Domain / Subdomain Human AI Other Intent. Unintent. Other Pre- dep. Post-dep. Other 1 Discrimination & toxicity 1.1 Unfair discrimination and misrepresentation 15% 70% 15% 3% 80% 18% 18% 61% 22% 1.2 Exposure to toxic content 11% 82% 8% 11% 26% 64% 6% 88% 6% 1.3 Unequal performance across groups 25% 56% 19% 6% 88% 6% 19% 50% 31% 2 Privacy & security 2.1 Compromise of privacy by obtaining, leaking or correctly inferring sensitive information 27% 58% 15% 14% 53% 33% 15% 61% 24% 2.2 AI system security vulnerabilities and attacks 77% 6% 16% 73% 15% 11% 22% 58% 21% 3 Misinformation 3.1 False or misleading information 2% 90% 7% 10% 71% 20% 5% 85% 10% 3.2 Pollution of information ecosystem and loss of consensus reality 28% 44% 28% 6% 44% 50% 89% 11% 4 Malicious actors & misuse 4.1 Disinformation, surveillance, and influence at scale 70% 12% 18% 90% 10% 90% 10% 4.2 Cyberattacks, weapon development or use, and mass harm 76% 15% 9% 85% 1% 13% 3% 88% 9% 4.3 Fraud, scams, and targeted manipulation 79% 6% 15% 81% 1% 18% 93% 7% 5 Human-computer interaction 5.1 Overreliance and unsafe use 45% 22% 33% 12% 61% 27% 94% 6% 5.2 Loss of human agency and autonomy 29% 26% 45% 16% 39% 45% 74% 26% 6 Socioeconomic & environmental harms 6.1 Power centralization and unfair distribution of benefits 72% 4% 23% 38% 28% 34% 4% 51% 45% 6.2 Increased inequality and decline in employment quality 52% 32% 16% 41% 11% 48% 11% 77% 11% 6.3 Economic and cultural devaluation of human effort 50% 37% 13% 37% 20% 43% 13% 60% 27% 6.4 Competitive dynamics 68% 11% 21% 42% 42% 16% 21% 26% 53% 6.5 Governance failure