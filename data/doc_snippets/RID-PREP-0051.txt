Repository ID: RID-PREP-0051
Source: AI_Risk_Repository_Preprint.docx
Section: Unknown
Content Type: future_work
Word Count: 772

Content:
Risk and Reliability Benchmark from MLCommons Journal Article NVIDIA Industry USA 10.48550/arXiv.2503.05731 Expert consultation 58 Abercrombie 2024 A Collaborative, Human-Centred Taxonomy of AI, Algorithmic, and Automation Harms Journal Article Heriot-Watt University University Scotland 10.48550/arXiv.2407.01294 Expert consultation 59 Schnitzer 2024 AI Hazard Management: A Framework for the Systematic Management of Root Causes for AI Risks Journal Article Technical University of Munich University Germany 10.48550/arXiv.2310.16727 Expert consultation 60 Bengio 2025 International AI Safety Report 2025 Report Université de Montréal University Canada - Expert consultation 61 Uuk 2025 A Taxonomy of Systemic Risks from General-Purpose AI Journal Article Future of Life Institute NGO Germany 10.2139/ssrn.5030173 Expert consultation 62 Gipiškis 2024 Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems Journal Article AI Standards Lab NGO Lithuania 10.48550/arXiv.2410.23472 Expert consultation 63 Hammond 2025 Multi-Agent Risks from Advanced AI Journal Article Cooperative AI Foundation NGO UK 10.48550/arXiv.2502.14143 Expert consultation 64 Marchal 2024 Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data Journal Article Google Deepmind Industry USA 10.48550/arXiv.2406.13843 Expert consultation 65 IBM 2025 AI Risk Atlas Website IBM Research Industry Switzerland - Expert consultation Declarations James Dao and Soroush Pour are employees of Harmony Intelligence, a company that conducts evaluations of AI risks. References AI Verify Foundation. (2023). Summary Report for Binary Classification Model of Credit Risk. AI Verify Foundation. Allianz Global Corporate & Security. (2018). The rise of artificial intelligence: future outlooks and emerging risks. Allianz Global Corporate & Specialty SE . https://commercial.allianz.com/news-and-insights/reports/the-rise-of-artificial-intelligence.html Althaus, D., & Baumann, T. (2020). Reducing long-term risks from malevolent actors. Publications of Center of Long Term Risk. Anderson-Samways, B., Ee, S., O’Brien, J., Buhl, M., & Williams, Z. (2024). Responsible Scaling: Comparing Government Guidance and Company Policy. Institute for AI Policy and Strategy. https://static1.squarespace.com/static/64edf8e7f2b10d716b5ba0e1/t/65f19a4a32c41d331ec54b87/1710332491804/Responsible+Scaling_+Comparing+Government+Guidance+and+Company+Policy+%284%29.pdf Anthropic. (2023). Anthropic’s responsible scaling policy. https://www-cdn.anthropic.com/1adf000c8f675958c2ee23805d91aaade1cd4613/responsible-scaling-policy.pdf Aven, T. (2012). The risk concept—historical and recent development trends. Reliability Engineering & System Safety, 99, 33–44. https://doi.org/10.1016/j.ress.2011.11.006 Aven, T., Ben-Haim, Y., Boje Andersen, H., Cox, T., Droguett, E. L., Greenberg, M., Guikema, S., Kröger, W., Renn, O., & Thompson, K. M. (2018). Society for risk analysis glossary. Bastos, M. T., & Mercea, D. (2019). The Brexit Botnet and User-Generated Hyperpartisan News. Social Science Computer Review, 37(1), 38–54. https://doi.org/10.1177/0894439317734157 Boetje, J., & van de Schoot, R. (2024). The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses. Systematic Reviews, 13(1), 81. https://doi.org/10.1186/s13643-024-02502-7 Bourget, D., & Chalmers, D. (n.d.). PHILOSOPHERS ON PHILOSOPHY: THE 2020 PHILPAPERS SURVEY. Brand, M., Rumpf, H.-J., Demetrovics, Z., MÜller, A., Stark, R., King, D. L., Goudriaan, A. E., Mann, K., Trotzke, P., Fineberg, N. A., Chamberlain, S. R., Kraus, S. W., Wegmann, E., Billieux, J., & Potenza, M. N. (2020). Which conditions should be considered as disorders in the International Classification of Diseases (ICD-11) designation of “other specified disorders due to addictive behaviors”? Journal of Behavioral Addictions, 11(2), 150–159. https://doi.org/10.1556/2006.2020.00035 Campos, D. G., Fütterer, T., Gfrörer, T., Lavelle-Hill, R., Murayama, K., König, L., Hecht, M., Zitzmann, S., & Scherer, R. (2024). Screening Smarter, Not Harder: A Comparative Analysis of Machine Learning Screening Algorithms and Heuristic Stopping Criteria for Systematic Reviews in Educational Research. Educational Psychology Review, 36(1), 19. https://doi.org/10.1007/s10648-024-09862-5 Carroll, C., Booth, A., & Cooper, K. (2011). A worked example of “best fit” framework synthesis: a systematic review of views concerning the taking of some potential chemopreventive agents. BMC Medical Research Methodology, 11, 29. https://doi.org/10.1186/1471-2288-11-29 Carroll, C., Booth, A., Leaviss, J., & Rick, J. (2013). “Best fit” framework synthesis: refining the method. BMC Medical Research Methodology, 13, 37. https://doi.org/10.1186/1471-2288-13-37 Castaño-Pulgarín, S. A., Suárez-Betancur, N., Vega, L. M. T., & López, H. M. H. (2021). Internet, social media and online hate speech. Systematic review. Aggression and Violent Behavior, 58, 101608. https://doi.org/10.1016/j.avb.2021.101608 Center for AI Safety. (2023, May 30). Statement on AI Risk. Center for AI Safety. https://www.safe.ai/work/statement-on-ai-risk Charmaz, K. (2006). Constructing Grounded Theory: A Practical Guide through Qualitative Analysis. SAGE. https://play.google.com/store/books/details?id=2ThdBAAAQBAJ Chinese National Information Security Standardization Technical Committee. (2023). Basic Safety Requirements for Generative Artificial Intelligence Services (Draft for Feedback). https://perma.cc/FBZ3-BW9S Committee on Technology. (2021). A Local Law to amend the administrative code of the city of New York, in relation to automated employment decision tools. https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4344524&GUID=B051915D-A9AC-451E-81F8-6596032FA3F9&Options=ID%7cText%7c&Search= Corbin, J., & Strauss, A. (2014). Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory. SAGE Publications. https://play.google.com/store/books/details?id=hZ6kBQAAQBAJ Costanza-Chock, S., Raji, I. D., & Buolamwini, J. (2022). Who Audits the Auditors? Recommendations from a field scan of the algorithmic auditing ecosystem. Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency, 1571–1583. https://doi.org/10.1145/3531146.3533213 Critch, A., & Russell, S. (2023). TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI. In arXiv [cs.AI]. arXiv. http://arxiv.org/abs/2306.06924