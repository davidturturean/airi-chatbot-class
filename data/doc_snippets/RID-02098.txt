Repository ID: RID-02098
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_situation: Title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data\nDomain: 2
sheet: AI Risk Database v3
rid: RID-02098
search_medium_priority: 2.2 > AI system security vulnerabilities and attacks 2.2 > AI system security vulnerabilities and attacks
row: 2075
entity: 1 - Human
search_high_priority: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data 2. Privacy & Security Misuse tactics to compromise GenAI systems (Model integrity)
search_low_priority: AI Risk Database v3 ai_risk_entry
timing: 2 - Post-deployment
risk_category: Misuse tactics to compromise GenAI systems (Model integrity)
scqa_confidence: 1.0
subdomain: 2.2 > AI system security vulnerabilities and attacks
intent: 1 - Intentional
domain: 2. Privacy & Security
title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data
scqa_content_type: risk_description
scqa_question: What are the implications of this risk?
specific_domain: 2.2 > AI system security vulnerabilities and attacks
content_preview: Title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data\nDomain: 2. Privacy & Security\nSub-domain: 2.2 > AI system security vulnerabilities and attacks\nRisk Category: Misuse tactics to compromise GenAI systems (Model integrity)\nRisk Subcategory: Adversarial input\nDes...
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_answer: 6"\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 2 - Post-deployment
file_type: ai_risk_entry
scqa_complication: ) and can be applied to text, but also to images, audio, or video (e.g. changing pixels in an image of a panda in a way that causes a model to label it a
search_all_fields: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data 2. Privacy & Security Misuse tactics to compromise GenAI systems (Model integrity) 2.2 > AI system security vulnerabilities and attacks 2.2 > AI system security vulnerabilities and attacks AI Risk Database v3 ai_risk_entry

Content:
Title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data\nDomain: 2. Privacy & Security\nSub-domain: 2.2 > AI system security vulnerabilities and attacks\nRisk Category: Misuse tactics to compromise GenAI systems (Model integrity)\nRisk Subcategory: Adversarial input\nDescription: "Adversarial Inputs involve modifying individual input data to cause a model to malfunction. These modifications, which are often imperceptible to humans, exploit how the model makes decisions to produce errors (Wallace et al., 2019) and can be applied to text, but also to images, audio, or video (e.g. changing pixels in an image of a panda in a way that causes a model to label it as a gibbon).6"\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 2 - Post-deployment