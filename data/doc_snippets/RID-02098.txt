Repository ID: RID-02098
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
file_type: ai_risk_entry
scqa_complication: ) and can be applied to text, but also to images, audio, or video (e.g. changing pixels in an image of a panda in a way that causes a model to label it a
domain: 2. Privacy & Security
content_preview: Title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data\nDomain: 2. Privacy & Security\nSub-domain: 2.2 > AI system security vulnerabilities and attacks\nRisk Category: Misuse tactics to compromise GenAI systems (Model integrity)\nRisk Subcategory: Adversarial input\nDes...
row: 2075
timing: 2 - Post-deployment
search_medium_priority: 2.2 > AI system security vulnerabilities and attacks 2.2 > AI system security vulnerabilities and attacks
specific_domain: 2.2 > AI system security vulnerabilities and attacks
scqa_confidence: 1.0
intent: 1 - Intentional
scqa_answer: 6"\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 2 - Post-deployment
entity: 1 - Human
search_low_priority: AI Risk Database v3 ai_risk_entry
title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data
subdomain: 2.2 > AI system security vulnerabilities and attacks
search_all_fields: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data 2. Privacy & Security Misuse tactics to compromise GenAI systems (Model integrity) 2.2 > AI system security vulnerabilities and attacks 2.2 > AI system security vulnerabilities and attacks AI Risk Database v3 ai_risk_entry
sheet: AI Risk Database v3
risk_category: Misuse tactics to compromise GenAI systems (Model integrity)
rid: RID-02098
scqa_question: What are the implications of this risk?
search_high_priority: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data 2. Privacy & Security Misuse tactics to compromise GenAI systems (Model integrity)
scqa_situation: Title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data\nDomain: 2
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_content_type: risk_description

Content:
Title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data\nDomain: 2. Privacy & Security\nSub-domain: 2.2 > AI system security vulnerabilities and attacks\nRisk Category: Misuse tactics to compromise GenAI systems (Model integrity)\nRisk Subcategory: Adversarial input\nDescription: "Adversarial Inputs involve modifying individual input data to cause a model to malfunction. These modifications, which are often imperceptible to humans, exploit how the model makes decisions to produce errors (Wallace et al., 2019) and can be applied to text, but also to images, audio, or video (e.g. changing pixels in an image of a panda in a way that causes a model to label it as a gibbon).6"\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 2 - Post-deployment