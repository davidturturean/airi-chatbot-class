Repository ID: RID-02098
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
risk_category: Misuse tactics to compromise GenAI systems (Model integrity)
search_low_priority: AI Risk Database v3 ai_risk_entry
specific_domain: 2.2 > AI system security vulnerabilities and attacks
scqa_confidence: 1.0
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
search_high_priority: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data 2. Privacy & Security Misuse tactics to compromise GenAI systems (Model integrity)
subdomain: 2.2 > AI system security vulnerabilities and attacks
content_preview: Title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data\nDomain: 2. Privacy & Security\nSub-domain: 2.2 > AI system security vulnerabilities and attacks\nRisk Category: Misuse tactics to compromise GenAI systems (Model integrity)\nRisk Subcategory: Adversarial input\nDes...
intent: 1 - Intentional
scqa_content_type: risk_description
scqa_answer: 6"\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 2 - Post-deployment
search_medium_priority: 2.2 > AI system security vulnerabilities and attacks 2.2 > AI system security vulnerabilities and attacks
sheet: AI Risk Database v3
entity: 1 - Human
rid: RID-02098
row: 2075
domain: 2. Privacy & Security
scqa_complication: ) and can be applied to text, but also to images, audio, or video (e.g. changing pixels in an image of a panda in a way that causes a model to label it a
timing: 2 - Post-deployment
title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data
scqa_situation: Title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data\nDomain: 2
file_type: ai_risk_entry
search_all_fields: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data 2. Privacy & Security Misuse tactics to compromise GenAI systems (Model integrity) 2.2 > AI system security vulnerabilities and attacks 2.2 > AI system security vulnerabilities and attacks AI Risk Database v3 ai_risk_entry
scqa_question: What are the implications of this risk?

Content:
Title: Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data\nDomain: 2. Privacy & Security\nSub-domain: 2.2 > AI system security vulnerabilities and attacks\nRisk Category: Misuse tactics to compromise GenAI systems (Model integrity)\nRisk Subcategory: Adversarial input\nDescription: "Adversarial Inputs involve modifying individual input data to cause a model to malfunction. These modifications, which are often imperceptible to humans, exploit how the model makes decisions to produce errors (Wallace et al., 2019) and can be applied to text, but also to images, audio, or video (e.g. changing pixels in an image of a panda in a way that causes a model to label it as a gibbon).6"\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 2 - Post-deployment