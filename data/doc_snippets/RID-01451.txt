Repository ID: RID-01451
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_content_type: risk_description
search_all_fields: Advancing AI Governance: A Literature Review of Problems, Options, and Proposals 4. Malicious Actors & Misuse Dangerous capabilities in AI systems 4.2 > Cyberattacks, weapon development or use, and mass harm 4.2 > Cyberattacks, weapon development or use, and mass harm AI Risk Database v3 ai_risk_entry
sheet: AI Risk Database v3
intent: 1 - Intentional
content_preview: Title: Advancing AI Governance: A Literature Review of Problems, Options, and Proposals\nDomain: 4. Malicious Actors & Misuse\nSub-domain: 4.2 > Cyberattacks, weapon development or use, and mass harm\nRisk Category: Dangerous capabilities in AI systems\nRisk Subcategory: Acquisition of a goal to har...
row: 1428
subdomain: 4.2 > Cyberattacks, weapon development or use, and mass harm
search_low_priority: AI Risk Database v3 ai_risk_entry
risk_category: Dangerous capabilities in AI systems
file_type: ai_risk_entry
scqa_answer: 2 > Cyberattacks, weapon development or use, and mass harm\nRisk Category: Dangerous capabilities in AI systems\nRisk Subcategory: Acquisition of a goal to harm society\nDescription: "cases of AI systems being given the outright goal of harming humanity (ChaosGPT);"\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 1 - Pre-deployment
scqa_situation: mass harm\nRisk Category: Dangerous capabilities in AI systems\nRisk Subcategory: Acquisition of a goal to harm society\nDescription: "cases of AI systems being g
specific_domain: 4.2 > Cyberattacks, weapon development or use, and mass harm
scqa_confidence: 1.0
title: Advancing AI Governance: A Literature Review of Problems, Options, and Proposals
search_medium_priority: 4.2 > Cyberattacks, weapon development or use, and mass harm 4.2 > Cyberattacks, weapon development or use, and mass harm
rid: RID-01451
scqa_question: What are the implications of this risk?
scqa_complication: opment or use, and mass harm\nRisk Category: Dangerous capabilities in AI systems\nRisk Subcategory: Acquisition of a goal to harm society\nDescription: "
entity: 1 - Human
search_high_priority: Advancing AI Governance: A Literature Review of Problems, Options, and Proposals 4. Malicious Actors & Misuse Dangerous capabilities in AI systems
timing: 1 - Pre-deployment
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
domain: 4. Malicious Actors & Misuse

Content:
Title: Advancing AI Governance: A Literature Review of Problems, Options, and Proposals\nDomain: 4. Malicious Actors & Misuse\nSub-domain: 4.2 > Cyberattacks, weapon development or use, and mass harm\nRisk Category: Dangerous capabilities in AI systems\nRisk Subcategory: Acquisition of a goal to harm society\nDescription: "cases of AI systems being given the outright goal of harming humanity (ChaosGPT);"\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 1 - Pre-deployment