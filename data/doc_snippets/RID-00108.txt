Repository ID: RID-00108
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
timing: 2 - Post-deployment
scqa_content_type: risk_description
scqa_complication: ge Models: A Survey on Safety Risks, Evaluations, and Improvements\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misr
domain: 1. Discrimination & Toxicity
entity: 3 - Other
scqa_answer: \nEntity: 3 - Other\nIntent: 3 - Other\nTiming: 2 - Post-deployment
risk_category: Unfairness and Discrimination
row: 85
search_low_priority: AI Risk Database v3 ai_risk_entry
subdomain: 1.1 > Unfair discrimination and misrepresentation
intent: 3 - Other
search_high_priority: Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements 1. Discrimination & Toxicity Unfairness and Discrimination
scqa_question: What are the implications of this risk?
content_preview: Title: Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: Unfairness and Discrimination\nDescription: Social bias is an unfairly negativ...
scqa_situation: Title: Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements\nDomain: 1
search_all_fields: Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements 1. Discrimination & Toxicity Unfairness and Discrimination 1.1 > Unfair discrimination and misrepresentation 1.1 > Unfair discrimination and misrepresentation AI Risk Database v3 ai_risk_entry
specific_domain: 1.1 > Unfair discrimination and misrepresentation
file_type: ai_risk_entry
title: Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements
scqa_confidence: 1.0
search_medium_priority: 1.1 > Unfair discrimination and misrepresentation 1.1 > Unfair discrimination and misrepresentation
rid: RID-00108
sheet: AI Risk Database v3
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx

Content:
Title: Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.1 > Unfair discrimination and misrepresentation\nRisk Category: Unfairness and Discrimination\nDescription: Social bias is an unfairly negative attitude towards a social group or individuals based on one-sided or inaccurate information, typically pertaining to widely disseminated negative stereotypes regarding gender, race, religion, etc.\nEntity: 3 - Other\nIntent: 3 - Other\nTiming: 2 - Post-deployment