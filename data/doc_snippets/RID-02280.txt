Repository ID: RID-02280
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
sheet: AI Risk Database v3
content_preview: AI Risk Domain: 5.1 > Overreliance and unsafe use\n\nThis domain contains 51 risk entries from the AI Risk Repository:\n\nRisk Entry 1:\nTitle: Mapping the Ethics of Generative AI: A Comprehensive Scoping Review\nDomain: 5. Human-Computer Interaction\nSub-domain: 5.1 > Overreliance and unsafe use\nR...
summary_type: domain_aggregation
rid: RID-02280
scqa_confidence: 1.0
search_low_priority: AI Risk Database v3 ai_risk_domain_summary
search_all_fields: AI Risk Domain: 5.1 > Overreliance and unsafe use 5.1 > Overreliance and unsafe use 5.1 > Overreliance and unsafe use AI Risk Database v3 ai_risk_domain_summary
scqa_question: What are the implications of this risk?
file_type: ai_risk_domain_summary
is_summary: True
scqa_situation: in: 5.1 > Overreliance and unsafe use\n\nThis domain contains 51 risk entries from the AI Risk Repository:\n\nRisk Entry 1:\nTitle: Mapping the Ethics of Generative AI: A Comprehensive Scoping Review\nDomain: 5. Human-Computer Interaction\nSub-domain: 5.1 > Overreliance and unsafe use\nRisk Category: Interaction risks\nDescription: Many novel risks posed by generative AI stem from the ways in which humans interact with these systems. For instance, sources discuss epistemic challenges in distinguishing AI-generated from human conte
search_medium_priority: 5.1 > Overreliance and unsafe use
scqa_complication: ample, users may falsely attribute human-like characteristics to CAs such as holding a coherent identity over time, or being capable of empathy. Such inf
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
specific_domain: 5.1 > Overreliance and unsafe use
domain: 5.1 > Overreliance and unsafe use
scqa_content_type: case_study
entry_count: 51
title: AI Risk Domain: 5.1 > Overreliance and unsafe use
search_high_priority: AI Risk Domain: 5.1 > Overreliance and unsafe use 5.1 > Overreliance and unsafe use
scqa_answer: they may place undue confidence, trust, or expectations in these agents...This can result in different risks of harm, for example when human users re

Content:
Anticipated risk: "Natural language is a mode of communication particularly used by humans. Humans interacting with CAs may come to think of these agents as human-like and lead users to place undue confidence in these agents. For example, users may falsely attribute human-like characteristics to CAs such as holding a coherent identity over time, or being capable of empathy. Such inflated views of CA competen- cies may lead users to rely on the agents where this is not safe."\nAdditional Evidence: "Google’s research arm People and AI Research (PAIR) found that ‘when users confuse an AI with a human being, they can sometimes disclose more information than they would otherwise, or rely on the system more than they should’ [138]. Similarly, in other interac- tive technologies it was found that the more human-like a system appears, the more likely it is that users attribute more human traits and capabilities to that system [29, 126,208]."\nEntity: 1 - Human\nIntent: 2 -