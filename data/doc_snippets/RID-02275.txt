Repository ID: RID-02275
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
search_all_fields: AI Risk Domain: 2.2 > AI system security vulnerabilities and attacks 2.2 > AI system security vulnerabilities and attacks 2.2 > AI system security vulnerabilities and attacks AI Risk Database v3 ai_risk_domain_summary
title: AI Risk Domain: 2.2 > AI system security vulnerabilities and attacks
file_type: ai_risk_domain_summary
search_high_priority: AI Risk Domain: 2.2 > AI system security vulnerabilities and attacks 2.2 > AI system security vulnerabilities and attacks
domain: 2.2 > AI system security vulnerabilities and attacks
rid: RID-02275
scqa_complication: of LLMs often relies on distributed network systems [171], [172]. During the transmission of gradients through the links between GPU server nodes, signif
entry_count: 98
scqa_question: What are the implications of this risk?
specific_domain: 2.2 > AI system security vulnerabilities and attacks
summary_type: domain_aggregation
scqa_confidence: 1.0
scqa_content_type: mitigation_strategy
scqa_situation: iption: "Pre-processing tools play a crucial role in the context of LLMs. These tools, which are often involved in computer vision (CV) tasks, are susceptible to attac
search_medium_priority: 2.2 > AI system security vulnerabilities and attacks
scqa_answer: , and Assessment Benchmarks of Large Language Model Systems\nDomain: 2. Privacy & Security\nSub-domain: 2.2 > AI system security vulnerabilities and a
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
sheet: AI Risk Database v3
content_preview: AI Risk Domain: 2.2 > AI system security vulnerabilities and attacks\n\nThis domain contains 98 risk entries from the AI Risk Repository:\n\nRisk Entry 1:\nTitle: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 2. Privacy & Security\nSub-domain: 2.2 > AI...
search_low_priority: AI Risk Database v3 ai_risk_domain_summary
is_summary: True

Content:
Hardware Vulnerabilities\nRisk Subcategory: Network Devices\nDescription: "The training of LLMs often relies on distributed network systems [171], [172]. During the transmission of gradients through the links between GPU server nodes, significant volumetric traffic is generated. This traffic can be susceptible to disruption by burst traffic, such as pulsating attacks [161]. Furthermore, distributed training frameworks may encounter congestion issues [173]."\nEntity: 3 - Other\nIntent: 2 - Unintentional\nTiming: 1 - Pre-deployment\n\nRisk Entry 9:\nTitle: Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems\nDomain: 2. Privacy & Security\nSub-domain: 2.2 > AI system security vulnerabilities and attacks\nRisk Category: Hardware Vulnerabilities\nRisk Subcategory: GPU Computation Platforms\nDescription: "The training of LLMs requires significant GPU resources, thereby introducing an additional security concern. GPU side-channel attacks have been developed