Repository ID: RID-00208
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.3 > Unequal performance across groups\nRisk Category: Quality-of-Service Harms\nRisk Subcategory: Increased labor\nDescription: increased burden (e.g., time ...
domain: 1. Discrimination & Toxicity
entity: 3 - Other
file_type: ai_risk_entry
intent: 2 - Unintentional
rid: RID-00208
risk_category: Quality-of-Service Harms
row: 185
scqa_answer: I feel at times, voice recognition isn't programmed to understand people when they're not speaking in a certain way"\nEntity: 3 - Other\nIntent: 2 - Unintentional\nTiming: 2 - Post-deployment
scqa_complication: al performance across groups\nRisk Category: Quality-of-Service Harms\nRisk Subcategory: Increased labor\nDescription: increased burden (e.g., time spent)
scqa_confidence: 1.0
scqa_content_type: risk_description
scqa_question: What are the implications of this risk?
scqa_situation: time spent) or effort required by members of certain social groups to make systems or products work as well for them as others\nAdditional Evidence: "I modify the way I talk to get a
search_all_fields: Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction 1. Discrimination & Toxicity Quality-of-Service Harms 1.3 > Unequal performance across groups 1.3 > Unequal performance across groups AI Risk Database v3 ai_risk_entry
search_high_priority: Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction 1. Discrimination & Toxicity Quality-of-Service Harms
search_low_priority: AI Risk Database v3 ai_risk_entry
search_medium_priority: 1.3 > Unequal performance across groups 1.3 > Unequal performance across groups
sheet: AI Risk Database v3
specific_domain: 1.3 > Unequal performance across groups
subdomain: 1.3 > Unequal performance across groups
timing: 2 - Post-deployment
title: Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction

Content:
Title: Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction\nDomain: 1. Discrimination & Toxicity\nSub-domain: 1.3 > Unequal performance across groups\nRisk Category: Quality-of-Service Harms\nRisk Subcategory: Increased labor\nDescription: increased burden (e.g., time spent) or effort required by members of certain social groups to make systems or products work as well for them as others\nAdditional Evidence: "I modify the way I talk to get a clear and concise response. I feel at times, voice recognition isn't programmed to understand people when they're not speaking in a certain way"\nEntity: 3 - Other\nIntent: 2 - Unintentional\nTiming: 2 - Post-deployment