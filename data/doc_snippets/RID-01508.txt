Repository ID: RID-01508
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nRisk Category: AI leads to humans losing control of the future\nAdditional Evidence: "The obvious question is: why would we develop advanced AI syst...
domain: Unspecified
entity: 
file_type: ai_risk_entry
intent: 
rid: RID-01508
risk_category: AI leads to humans losing control of the future
row: 1485
scqa_answer: Indeed, notice that there are many objectives a system could learn that will lead it to score highly on the training objective but which do not lead to desirable behaviour over the long run
scqa_complication: t scraped from the internet”. However, this approach gives no guarantee that a system will continue to pursue the training objective as intended over the long
scqa_confidence: 1.0
scqa_content_type: impact_analysis
scqa_question: Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nRisk Category: AI leads to humans losing control of the future\nAdditional Evidence: "The obvious question is: why would we develop advanced AI systems that are willing and able to take control of the future?
scqa_situation: cts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nRisk Category: AI leads to humans losing control of the future\nAdditional Evidence: "The obvious question is: why would we develop advanced AI systems that are willing and able to take control of the future? One major concern is that we don't yet hav
search_all_fields: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values Unspecified AI leads to humans losing control of the future Unspecified AI Risk Database v3 ai_risk_entry
search_high_priority: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values Unspecified AI leads to humans losing control of the future
search_low_priority: AI Risk Database v3 ai_risk_entry
search_medium_priority: Unspecified
sheet: AI Risk Database v3
specific_domain: Unspecified
subdomain: 
timing: 
title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx

Content:
Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nRisk Category: AI leads to humans losing control of the future\nAdditional Evidence: "The obvious question is: why would we develop advanced AI systems that are willing and able to take control of the future? One major concern is that we don't yet have ways of designing AI systems that reliably do what their designers want. Instead, modern AI training14 works by (roughly speaking) tweaking a system's “parameters” many times, until it scores highly according to some given “training objective”, evaluated on some “training data”. For instance, the large language model GPT-3 [7] is trained by (roughly speaking) tweaking its parameters until it scores highly at “predicting the next word” on “text scraped from the internet”. However, this approach gives no guarantee that a system will continue to pursue the training objective as intended over the long run. Indeed, notice that there are many objectives a system could learn that will lead it to score highly on the training objective but which do not lead to desirable behaviour over the long run."