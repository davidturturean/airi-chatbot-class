Repository ID: RID-01508
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
search_all_fields: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values Unspecified AI leads to humans losing control of the future Unspecified AI Risk Database v3 ai_risk_entry
rid: RID-01508
domain: Unspecified
title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values
subdomain: 
entity: 
row: 1485
timing: 
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
risk_category: AI leads to humans losing control of the future
scqa_answer: Indeed, notice that there are many objectives a system could learn that will lead it to score highly on the training objective but which do not lead to desirable behaviour over the long run
search_low_priority: AI Risk Database v3 ai_risk_entry
file_type: ai_risk_entry
content_preview: Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nRisk Category: AI leads to humans losing control of the future\nAdditional Evidence: "The obvious question is: why would we develop advanced AI syst...
search_high_priority: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values Unspecified AI leads to humans losing control of the future
specific_domain: Unspecified
sheet: AI Risk Database v3
scqa_question: Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nRisk Category: AI leads to humans losing control of the future\nAdditional Evidence: "The obvious question is: why would we develop advanced AI systems that are willing and able to take control of the future?
scqa_confidence: 1.0
scqa_content_type: impact_analysis
intent: 
search_medium_priority: Unspecified
scqa_situation: cts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nRisk Category: AI leads to humans losing control of the future\nAdditional Evidence: "The obvious question is: why would we develop advanced AI systems that are willing and able to take control of the future? One major concern is that we don't yet hav
scqa_complication: t scraped from the internet”. However, this approach gives no guarantee that a system will continue to pursue the training objective as intended over the long

Content:
Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nRisk Category: AI leads to humans losing control of the future\nAdditional Evidence: "The obvious question is: why would we develop advanced AI systems that are willing and able to take control of the future? One major concern is that we don't yet have ways of designing AI systems that reliably do what their designers want. Instead, modern AI training14 works by (roughly speaking) tweaking a system's “parameters” many times, until it scores highly according to some given “training objective”, evaluated on some “training data”. For instance, the large language model GPT-3 [7] is trained by (roughly speaking) tweaking its parameters until it scores highly at “predicting the next word” on “text scraped from the internet”. However, this approach gives no guarantee that a system will continue to pursue the training objective as intended over the long run. Indeed, notice that there are many objectives a system could learn that will lead it to score highly on the training objective but which do not lead to desirable behaviour over the long run."