Repository ID: RID-PREP-0010
Source: AI_Risk_Repository_Preprint.docx
Section: Unknown
Content Type: comparative_analysis
Word Count: 753

Content:
synthesis approach to develop two AI risk taxonomies. Best-fit framework synthesis is a method for rapidly, clearly, and practically understanding the relationships and structures between concepts in a topic area (Carroll et al., 2011, 2013). It combines the strengths of framework synthesis (Ritchie & Spencer, 2002), which is a “top down” positivist method where concepts are coded against a pre-existing structure, and thematic synthesis (Thomas & Harden, 2008), which is a “bottom up” interpretative method where concepts are iteratively analyzed to identify patterns and structure. We outline the process in Figure 2. Figure 2. Methodology for Best Fit Framework Synthesis To conduct a best-fit framework synthesis, we identified published frameworks in an area (through our systematic search and screening), selected the “best” existing framework for our purpose, then used that existing framework to code the concepts (i.e., all the risks extracted into the living AI Risk Database). Some risks could not be coded against the existing framework. We then conducted a secondary thematic analysis to identify new themes in those risks and determined what changes needed to be made to the framework to accommodate those themes. This involved updating the existing categories, creating new categories, or changing the structure of the framework. This process was repeated until achieving a final version of the framework that could most effectively code all relevant risks. By starting with an existing framework, the synthesis can achieve a coherent framework more quickly than inductively or thematically analyzing all the individual concepts (risks) across all included papers. The trade-off is that the existing framework creates a particular “lens” for understanding and categorizing the individual concepts, which may lead to a disconnect between the synthesized findings and the theoretical or epistemological perspectives in the original and highly varied papers. In order to mitigate this, we attempted to code the risks based on the exact wording the authors had presented rather than our interpretation of what they may have intended to communicate (cf. Charmaz, 2006; Corbin & Strauss, 2014). Why we developed two taxonomies of AI risk The goal of our best-fit framework synthesis was to create a common frame of reference for understanding and addressing the risks from artificial intelligence. We found that authors implicitly or explicitly used different lenses (e.g., Head, 2008; Nilsen, 2015; Sovacool & Hess, 2017) to create their frameworks. These lenses reveal and obscure different aspects of the AI risk landscape. Through our systematic search, we identified two types of frameworks, which we will refer to here as high- and mid-level frameworks. “High-level frameworks” focused on capturing broad factors that specify how, when, or why an AI risk might emerge (e.g., Critch & Russell, 2023; Kilian et al., 2023) rather than discuss categories of specific hazards and harms. In contrast, “Mid-level frameworks” focused on specific hazards and harms (e.g., Solaiman et al., 2023; Weidinger et al., 2021) but didn’t explore their causes. The fact that categorizations were at such different levels of specificity made it challenging to create a single framework. Often, specific mid-level risks did not fit into the categories within a high-level framework, and the broad categories in those frameworks were insufficiently specified to be useful, in isolation, for creating shared understanding. Similarly, broad high-level categorizations of how, when, or why an AI risk emerges did not fit with mid-level frameworks outlining narrow and specific sets of risk. We therefore resolved that the ideal common frame of reference required two intersecting taxonomies: one to precisely decompose or define an AI risk based on the high-level conditions under which it occurred (a “causal taxonomy”), and one that classified commonly discussed hazards and harms associated with AI into understandable and distinct domains (a “domain taxonomy”). In the following sections, we describe the process of developing these two taxonomies using a best-fit framework synthesis approach. Development of high-level Causal Taxonomy of AI Risks Best-fit taxonomy: Yampolskiy (2016) We chose Yampolskiy’s (2016) Taxonomy of pathways to dangerous AI as our initial best-fit framework for developing a causal taxonomy for AI risk. We selected Yampolskiy’s taxonomy as it was highly cited (116 citations, fifth most highly cited from the set of identified papers), simple, comprehensive, and provided sufficient definitions for each category. Yampolskiy’s taxonomy systematically classifies the ways in which an AI system might become dangerous based on two main factors: Timing - whether the AI became dangerous at the pre-deployment or post-deployment stage, and Cause - whether the danger arose from External Causes (On Purpose, By Mistake, Environment) or Internal Causes originating from the AI system itself (Independently).