Repository ID: RID-00899
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_confidence: 1.0
intent: 1 - Intentional
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
search_all_fields: AI Alignment: A Comprehensive Survey 7. AI System Safety, Failures, & Limitations Double edge components 7.2 > AI possessing dangerous capabilities 7.2 > AI possessing dangerous capabilities AI Risk Database v3 ai_risk_entry
entity: 1 - Human
scqa_question: What are the implications of this risk?
row: 876
file_type: ai_risk_entry
scqa_answer: "\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 2 - Post-deployment
title: AI Alignment: A Comprehensive Survey
search_medium_priority: 7.2 > AI possessing dangerous capabilities 7.2 > AI possessing dangerous capabilities
specific_domain: 7.2 > AI possessing dangerous capabilities
scqa_situation: g timeframes,deal with complex tasks, and operate in open-ended settings (Ngo et al., 2024). ...However, it can also bring about the risk of encouraging manipulatingbehaviors (e.g., AI systems may take some bad actions to achieve human happiness, such as persuadingthem to do high-pressure jo
domain: 7. AI System Safety, Failures, & Limitations
risk_category: Double edge components
search_low_priority: AI Risk Database v3 ai_risk_entry
sheet: AI Risk Database v3
timing: 2 - Post-deployment
content_preview: Title: AI Alignment: A Comprehensive Survey\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.2 > AI possessing dangerous capabilities\nRisk Category: Double edge components\nRisk Subcategory: Broadly-Scoped Goals\nDescription: "Advanced AI systems are expected to develop objectiv...
scqa_complication: ttings (Ngo et al., 2024). ...However, it can also bring about the risk of encouraging manipulatingbehaviors (e.g., AI systems may take some bad actions to ac
rid: RID-00899
subdomain: 7.2 > AI possessing dangerous capabilities
scqa_content_type: risk_description
search_high_priority: AI Alignment: A Comprehensive Survey 7. AI System Safety, Failures, & Limitations Double edge components

Content:
Title: AI Alignment: A Comprehensive Survey\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.2 > AI possessing dangerous capabilities\nRisk Category: Double edge components\nRisk Subcategory: Broadly-Scoped Goals\nDescription: "Advanced AI systems are expected to develop objectives that span long timeframes,deal with complex tasks, and operate in open-ended settings (Ngo et al., 2024). ...However, it can also bring about the risk of encouraging manipulatingbehaviors (e.g., AI systems may take some bad actions to achieve human happiness, such as persuadingthem to do high-pressure jobs (Jacob Steinhardt, 2023))."\nEntity: 1 - Human\nIntent: 1 - Intentional\nTiming: 2 - Post-deployment