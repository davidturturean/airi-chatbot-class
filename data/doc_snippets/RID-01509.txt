Repository ID: RID-01509
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_situation: cts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human
scqa_complication: t with human goals or values\nRisk Category: AI leads to humans losing control of the future\nRisk Subcategory: Risks from AIs developing goals and values
search_all_fields: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values 7. AI System Safety, Failures, & Limitations AI leads to humans losing control of the future 7.1 > AI pursuing its own goals in conflict with human goals or values 7.1 > AI pursuing its own goals in conflict with human goals or values AI Risk Database v3 ai_risk_entry
entity: 2 - AI
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_content_type: impact_analysis
content_preview: Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human goals or values\nRisk Categ...
domain: 7. AI System Safety, Failures, & Limitations
search_medium_priority: 7.1 > AI pursuing its own goals in conflict with human goals or values 7.1 > AI pursuing its own goals in conflict with human goals or values
scqa_answer: "\nEntity: 2 - AI\nIntent: 1 - Intentional\nTiming: 3 - Other
rid: RID-01509
risk_category: AI leads to humans losing control of the future
timing: 3 - Other
search_high_priority: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values 7. AI System Safety, Failures, & Limitations AI leads to humans losing control of the future
specific_domain: 7.1 > AI pursuing its own goals in conflict with human goals or values
file_type: ai_risk_entry
intent: 1 - Intentional
title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values
sheet: AI Risk Database v3
search_low_priority: AI Risk Database v3 ai_risk_entry
row: 1486
subdomain: 7.1 > AI pursuing its own goals in conflict with human goals or values
scqa_question: What are the implications of this risk?
scqa_confidence: 1.0

Content:
Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human goals or values\nRisk Category: AI leads to humans losing control of the future\nRisk Subcategory: Risks from AIs developing goals and values that are different from humans\nDescription: "The main concern here is that we might develop advanced AI systems whose goals and values are different from those of humans, and are capable enough to take control of the future away from humanity."\nEntity: 2 - AI\nIntent: 1 - Intentional\nTiming: 3 - Other