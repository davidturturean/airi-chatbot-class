Repository ID: RID-01509
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
scqa_complication: t with human goals or values\nRisk Category: AI leads to humans losing control of the future\nRisk Subcategory: Risks from AIs developing goals and values
scqa_content_type: impact_analysis
timing: 3 - Other
scqa_confidence: 1.0
domain: 7. AI System Safety, Failures, & Limitations
rid: RID-01509
row: 1486
search_all_fields: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values 7. AI System Safety, Failures, & Limitations AI leads to humans losing control of the future 7.1 > AI pursuing its own goals in conflict with human goals or values 7.1 > AI pursuing its own goals in conflict with human goals or values AI Risk Database v3 ai_risk_entry
scqa_question: What are the implications of this risk?
content_preview: Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human goals or values\nRisk Categ...
risk_category: AI leads to humans losing control of the future
scqa_answer: "\nEntity: 2 - AI\nIntent: 1 - Intentional\nTiming: 3 - Other
sheet: AI Risk Database v3
file_type: ai_risk_entry
title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values
subdomain: 7.1 > AI pursuing its own goals in conflict with human goals or values
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
search_low_priority: AI Risk Database v3 ai_risk_entry
scqa_situation: cts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human
entity: 2 - AI
search_medium_priority: 7.1 > AI pursuing its own goals in conflict with human goals or values 7.1 > AI pursuing its own goals in conflict with human goals or values
intent: 1 - Intentional
search_high_priority: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values 7. AI System Safety, Failures, & Limitations AI leads to humans losing control of the future
specific_domain: 7.1 > AI pursuing its own goals in conflict with human goals or values

Content:
Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human goals or values\nRisk Category: AI leads to humans losing control of the future\nRisk Subcategory: Risks from AIs developing goals and values that are different from humans\nDescription: "The main concern here is that we might develop advanced AI systems whose goals and values are different from those of humans, and are capable enough to take control of the future away from humanity."\nEntity: 2 - AI\nIntent: 1 - Intentional\nTiming: 3 - Other