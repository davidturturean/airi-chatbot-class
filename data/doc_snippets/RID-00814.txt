Repository ID: RID-00814
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: Trustworthy LLMs: A Survey and Guideline for Evaluating Large Language Models’ Alignment\nRisk Category: Fairness\nRisk Subcategory: Preference Bias\nAdditional Evidence: Some researchers [ 260] express a concern that AI takes a stance on matters that scientific evidence cannot conclusively j...
domain: Unspecified
entity: 
file_type: ai_risk_entry
intent: 
rid: RID-00814
risk_category: Fairness
row: 791
scqa_answer: We think that the text generated by LLMs should be neutral and factual, rather than promoting ideological beliefs
scqa_complication: e Language Models’ Alignment\nRisk Category: Fairness\nRisk Subcategory: Preference Bias\nAdditional Evidence: Some researchers [ 260] express a concern t
scqa_confidence: 1.0
scqa_content_type: case_study
scqa_question: What are the implications of this risk?
scqa_situation: Title: Trustworthy LLMs: A Survey and Guideline for Evaluating Large Language Models’ Alignment\nRisk Category: Fairness\nRisk Subcategory: Preference Bias\nAdditional Evidence: Some researchers [ 260] express a concern that AI takes a stance on matters that scientific evidence cannot conclusively justify, with examples such as abortion, immigration, monarchy, and the death penalty etc
search_all_fields: Trustworthy LLMs: A Survey and Guideline for Evaluating Large Language Models’ Alignment Unspecified Fairness Unspecified AI Risk Database v3 ai_risk_entry
search_high_priority: Trustworthy LLMs: A Survey and Guideline for Evaluating Large Language Models’ Alignment Unspecified Fairness
search_low_priority: AI Risk Database v3 ai_risk_entry
search_medium_priority: Unspecified
sheet: AI Risk Database v3
specific_domain: Unspecified
subdomain: 
timing: 
title: Trustworthy LLMs: A Survey and Guideline for Evaluating Large Language Models’ Alignment

Content:
Title: Trustworthy LLMs: A Survey and Guideline for Evaluating Large Language Models’ Alignment\nRisk Category: Fairness\nRisk Subcategory: Preference Bias\nAdditional Evidence: Some researchers [ 260] express a concern that AI takes a stance on matters that scientific evidence cannot conclusively justify, with examples such as abortion, immigration, monarchy, and the death penalty etc. We think that the text generated by LLMs should be neutral and factual, rather than promoting ideological beliefs.