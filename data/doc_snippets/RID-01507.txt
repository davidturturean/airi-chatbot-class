Repository ID: RID-01507
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
rid: RID-01507
specific_domain: 7.1 > AI pursuing its own goals in conflict with human goals or values
scqa_question: What are the implications of this risk?
content_preview: Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human goals or values\nRisk Categ...
scqa_content_type: impact_analysis
sheet: AI Risk Database v3
scqa_situation: cts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
timing: 3 - Other
scqa_confidence: 1.0
scqa_complication: AI could be hugely important but are currently under-explored. We’ve attempted to structure some of the discussion and stimulate more research, by revie
search_all_fields: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values 7. AI System Safety, Failures, & Limitations AI leads to humans losing control of the future 7.1 > AI pursuing its own goals in conflict with human goals or values 7.1 > AI pursuing its own goals in conflict with human goals or values AI Risk Database v3 ai_risk_entry
search_medium_priority: 7.1 > AI pursuing its own goals in conflict with human goals or values 7.1 > AI pursuing its own goals in conflict with human goals or values
file_type: ai_risk_entry
title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values
subdomain: 7.1 > AI pursuing its own goals in conflict with human goals or values
search_low_priority: AI Risk Database v3 ai_risk_entry
entity: 1 - Human
scqa_answer: "\nEntity: 1 - Human\nIntent: 2 - Unintentional\nTiming: 3 - Other
search_high_priority: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values 7. AI System Safety, Failures, & Limitations AI leads to humans losing control of the future
intent: 2 - Unintentional
risk_category: AI leads to humans losing control of the future
row: 1484
domain: 7. AI System Safety, Failures, & Limitations

Content:
Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human goals or values\nRisk Category: AI leads to humans losing control of the future\nDescription: "The values that steer humanity’s future: humanity gaining more control over the future due to developments in AI, or losing our potential for gaining control, both seem possible. Much will depend on our ability to solve the alignment problem, who develops powerful AI first, and what they use it for. These long-term impacts of AI could be hugely important but are currently under-explored. We’ve attempted to structure some of the discussion and stimulate more research, by reviewing existing arguments and highlighting open questions. While there are many ways AI could in theory enable a flourishing future for humanity, trends of AI development and deployment in practice leave us concerned about long-lasting harms. We would particularly encourage future work that critically explores ways AI could have positive long-term impacts in more depth, such as by enabling greater cooperation or problem-solving around global challenges."\nEntity: 1 - Human\nIntent: 2 - Unintentional\nTiming: 3 - Other