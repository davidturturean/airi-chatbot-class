Repository ID: RID-PREP-0007
Source: AI_Risk_Repository_Preprint.docx
Section: Domain Taxonomy
Content Type: comparative_analysis
Word Count: 785

Content:
risks, and the Causal Taxonomy and Domain Taxonomy of AI risks. The database and taxonomies can be used individually or in combination to explore the database, as well as for research, policy, and practice to address risks from AI. All of these artifacts are available online. The AI Risk Repository is, to our knowledge, the first attempt to rigorously curate, analyze, and extract AI risk frameworks into a publicly accessible, comprehensive, extensible, and categorized risk database. This creates a foundation for a more coordinated, coherent, and complete approach to defining, auditing, and managing the risks posed by AI systems. Methods We used a systematic search strategy, forwards and backwards searching, and expert consultation to identify AI risk classifications, frameworks, and taxonomies. Since conducting the original systematic literature search, we have periodically identified additional relevant research through an ongoing expert consultation. We extracted the individual risks from these documents into a living AI Risk Database. We conducted two best-fit framework syntheses to create a Causal Taxonomy of AI Risks (see Table 2) and Domain Taxonomy of AI Risks (see Table 6), by adapting existing frameworks (Weidinger et al., 2022; Yampolskiy, 2016). We did this by testing their effectiveness at coding our risk data and modifying them until we created a final version that could effectively code all relevant risks. Figure 1. Overview of Study Methodology We followed the Society for Risk Analysis (Aven et al., 2018) in defining “AI risk” as “the possibility of an unfortunate occurrence associated with the development or deployment of artificial intelligence,” while recognizing that this term can be defined in many ways (Aven, 2012; Li & Li, 2023). Systematic literature search We conducted this study as a rapid systematic review (Khangura et al., 2012; Tricco et al., 2017). The protocol was registered in advance using the Open Science Framework in April 2024 (https://osf.io/egzc8). We included reviews, articles, reports, and documents primarily focused on proposing new frameworks, taxonomies, or other structured classifications of risks from AI present across multiple locations and industry sectors. We excluded book chapters, theses, commentaries, editorials, and protocols. Our pilot searches suggested that including these documents would significantly increase the number of search results to screen but not the number of relevant results. We excluded documents which discussed impacts, outcomes, or other consequences of AI without specifying specific risks because we were interested in risk classification. Due to our interest in broad, structured classifications of risks from AI, we excluded documents which focused only on risks from AI that are present in a single location or sector or that discussed risks specific to particular risk categories (e.g., content solely focused on different types of unfair decision-making) or very specific AI tools (e.g., content solely focused on risks from DALL-E). We excluded content which merely cited or discussed existing theories, frameworks, models, taxonomies, and other structured classifications rather than proposing and explaining them. This was because we wanted to understand and extract specific risks using their original source material. We excluded anything which discussed sources of risk at a high level of abstraction (e.g., the sources of sociotechnical risk in AIs) or risk-assessment processes (e.g, how organizations can assess risks from AI) rather than focusing on classifying AI risks more specifically. Non-English articles, reports, and documents were excluded due to resource constraints related to their retrieval and translation. Two of the above exclusion criteria were added after protocol registration in order to retain only the most relevant documents: (1) Focus only on one category of risk from AI; (2) Focus on sources of risk or the risk-assessment process. Search strategy Our search strategy comprised two stages. In Stage 1 we conducted a systematic search of peer-reviewed and gray literature (i.e., non peer-reviewed materials) to identify relevant articles. We begin by explaining our search-term generation and strategy, followed by our database searches in Scopus and various preprint databases. We then describe our screening process, which utilizes active learning with ASReview. This process includes four phases: initial random screening for training data, application of active learning with specific stopping rules, model switching for comprehensive coverage, and quality evaluation. Finally, we outline our full-text screening and calibration procedures. In Stage 2 we conducted forwards (citation) and backwards (references) searching and expert consultation to identify additional eligible articles. The two stages are described below. Stage 1: Searching & screening peer reviewed and gray literature Searching Search terms were generated through an iterative process and chosen for their empirical balance between sensitivity and specificity (Wilczynski et al., 2003). This included terms related to artificial intelligence (Artificial intelligence, AI, Artificial general intelligence, AGI), frameworks, taxonomies, and other structured classifications (Framework, Review, Overview, Taxonomy*), and risks (Risk, Harm, Hazard). This led to the following search string: