Repository ID: RID-01511
Source: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx
content_preview: Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human goals or values\nRisk Categ...
domain: 7. AI System Safety, Failures, & Limitations
entity: 2 - AI
file_type: ai_risk_entry
intent: 1 - Intentional
rid: RID-01511
risk_category: AI leads to humans losing control of the future
row: 1488
scqa_answer: "\nEntity: 2 - AI\nIntent: 1 - Intentional\nTiming: 3 - Other
scqa_complication: t with human goals or values\nRisk Category: AI leads to humans losing control of the future\nRisk Subcategory: Risks from delegating decision-making powe
scqa_confidence: 1.0
scqa_content_type: impact_analysis
scqa_question: What are the implications of this risk?
scqa_situation: cts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human
search_all_fields: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values 7. AI System Safety, Failures, & Limitations AI leads to humans losing control of the future 7.1 > AI pursuing its own goals in conflict with human goals or values 7.1 > AI pursuing its own goals in conflict with human goals or values AI Risk Database v3 ai_risk_entry
search_high_priority: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values 7. AI System Safety, Failures, & Limitations AI leads to humans losing control of the future
search_low_priority: AI Risk Database v3 ai_risk_entry
search_medium_priority: 7.1 > AI pursuing its own goals in conflict with human goals or values 7.1 > AI pursuing its own goals in conflict with human goals or values
sheet: AI Risk Database v3
specific_domain: 7.1 > AI pursuing its own goals in conflict with human goals or values
subdomain: 7.1 > AI pursuing its own goals in conflict with human goals or values
timing: 3 - Other
title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values
url: data/info_files/The_AI_Risk_Repository_V3_26_03_2025.xlsx

Content:
Title: A Survey of the Potential Long-term Impacts of AI: How AI Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values\nDomain: 7. AI System Safety, Failures, & Limitations\nSub-domain: 7.1 > AI pursuing its own goals in conflict with human goals or values\nRisk Category: AI leads to humans losing control of the future\nRisk Subcategory: Risks from delegating decision-making power to misaligned AIs\nDescription: "As AI systems become more advanced a nd begin to take over more important decision-making in the world, an AI system pursuing a different objective from what was intended could have much more worrying consequences."\nEntity: 2 - AI\nIntent: 1 - Intentional\nTiming: 3 - Other